import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import cv2
import matplotlib.pyplot as plt
from PIL import Image
import os
import json
from collections import defaultdict
import argparse

# å¯¼å…¥æ¨¡å‹
from improved_color_combination import (
    ImprovedColorCombinationHead, 
    BalancedColorCombinationDataset,
    IMPROVED_COLOR_COMBINATIONS
)

class CAMGenerator:
    """CAM (Class Activation Mapping) ç”Ÿæˆå™¨"""
    
    def __init__(self, model_path, device='cuda'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.model = ImprovedColorCombinationHead(num_classes=5).to(self.device)
        
        # åŠ è½½æ¨¡å‹æƒé‡
        self.model.load_state_dict(torch.load(model_path, map_location=self.device))
        self.model.eval()
        
        # è·å–æœ€åä¸€ä¸ªå·ç§¯å±‚çš„ç‰¹å¾
        self.features = None
        self.gradients = None
        
        # æ³¨å†Œé’©å­
        self._register_hooks()
        
        print(f"âœ… æ¨¡å‹å·²åŠ è½½: {model_path}")
        print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {self.device}")
    
    def _register_hooks(self):
        """æ³¨å†Œé’©å­æ¥è·å–ç‰¹å¾å’Œæ¢¯åº¦"""
        def forward_hook(module, input, output):
            self.features = output
        
        def backward_hook(module, grad_input, grad_output):
            self.gradients = grad_output[0]
        
        # è·å–æœ€åä¸€ä¸ªå·ç§¯å±‚ï¼ˆç‰¹å¾æå–å™¨çš„æœ€åä¸€å±‚ï¼‰
        last_conv_layer = None
        for name, module in self.model.named_modules():
            if isinstance(module, nn.Conv2d):
                last_conv_layer = module
        
        if last_conv_layer is not None:
            last_conv_layer.register_forward_hook(forward_hook)
            last_conv_layer.register_backward_hook(backward_hook)
            print(f"âœ… å·²æ³¨å†Œé’©å­åˆ°å·ç§¯å±‚: {last_conv_layer}")
        else:
            print("âŒ æœªæ‰¾åˆ°å·ç§¯å±‚")
    
    def generate_cam(self, image, target_class=None):
        """ç”ŸæˆCAM"""
        # å‡†å¤‡è¾“å…¥
        if isinstance(image, np.ndarray):
            # å¦‚æœæ˜¯HWCæ ¼å¼ï¼Œè½¬æ¢ä¸ºCHWæ ¼å¼
            if image.shape[-1] == 3:  # HWC -> CHW
                image = np.transpose(image, (2, 0, 1))
            image = torch.FloatTensor(image).unsqueeze(0)
        elif isinstance(image, torch.Tensor):
            # å¦‚æœæ˜¯HWCæ ¼å¼ï¼Œè½¬æ¢ä¸ºCHWæ ¼å¼
            if image.shape[-1] == 3:  # HWC -> CHW
                image = image.permute(2, 0, 1)
            image = image.unsqueeze(0)
        
        image = image.to(self.device)
        image.requires_grad = True
        
        # å‰å‘ä¼ æ’­
        outputs = self.model(image)
        logits = outputs['combination_logits']
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šç›®æ ‡ç±»åˆ«ï¼Œä½¿ç”¨é¢„æµ‹çš„ç±»åˆ«
        if target_class is None:
            target_class = logits.argmax(dim=1).item()
        
        # è®¡ç®—ç›®æ ‡ç±»åˆ«çš„å¾—åˆ†
        score = logits[0, target_class]
        
        # åå‘ä¼ æ’­
        self.model.zero_grad()
        score.backward()
        
        # è·å–ç‰¹å¾å’Œæ¢¯åº¦
        if self.features is None or self.gradients is None:
            print("âŒ æ— æ³•è·å–ç‰¹å¾æˆ–æ¢¯åº¦")
            return None
        
        # è®¡ç®—æƒé‡
        weights = torch.mean(self.gradients, dim=(2, 3))
        
        # ç”ŸæˆCAM
        cam = torch.zeros(self.features.shape[2:], dtype=torch.float32, device=self.device)
        
        for i, w in enumerate(weights[0]):
            cam += w * self.features[0, i, :, :]
        
        # åº”ç”¨ReLU
        cam = F.relu(cam)
        
        # å½’ä¸€åŒ–
        cam = cam - cam.min()
        cam = cam / (cam.max() + 1e-8)
        
        return cam.detach().cpu().numpy()
    
    def visualize_cam(self, image, cam, save_path=None, alpha=0.6):
        """å¯è§†åŒ–CAM"""
        # ç¡®ä¿å›¾åƒæ˜¯numpyæ•°ç»„
        if isinstance(image, torch.Tensor):
            image = image.squeeze(0).cpu().numpy()
            if image.shape[0] == 3:  # CHW -> HWC
                image = np.transpose(image, (1, 2, 0))
        
        # è°ƒæ•´CAMå¤§å°ä»¥åŒ¹é…å›¾åƒ
        cam_resized = cv2.resize(cam, (image.shape[1], image.shape[0]))
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)
        heatmap = np.float32(heatmap) / 255
        
        # è½¬æ¢å›¾åƒæ ¼å¼
        if image.max() <= 1.0:
            image = np.uint8(255 * image)
        else:
            image = np.uint8(image)
        
        # å åŠ 
        cam_image = heatmap + alpha * np.float32(image) / 255
        cam_image = cam_image / np.max(cam_image)
        
        # åˆ›å»ºå¯è§†åŒ–
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # åŸå§‹å›¾åƒ
        axes[0].imshow(image)
        axes[0].set_title('åŸå§‹å›¾åƒ')
        axes[0].axis('off')
        
        # CAMçƒ­åŠ›å›¾
        axes[1].imshow(cam_resized, cmap='jet')
        axes[1].set_title('CAMçƒ­åŠ›å›¾')
        axes[1].axis('off')
        
        # å åŠ ç»“æœ
        axes[2].imshow(cam_image)
        axes[2].set_title('CAMå åŠ ')
        axes[2].axis('off')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"âœ… CAMå›¾ç‰‡å·²ä¿å­˜: {save_path}")
        
        plt.show()
        
        return cam_image

def create_test_images():
    """åˆ›å»ºæµ‹è¯•å›¾åƒ"""
    test_images = []
    
    # ä¸ºæ¯ä¸ªé¢œè‰²ç»„åˆåˆ›å»ºæµ‹è¯•å›¾åƒ
    for combo_id in range(5):
        combo = IMPROVED_COLOR_COMBINATIONS[combo_id]
        print(f"åˆ›å»º {combo['name']} æµ‹è¯•å›¾åƒ...")
        
        # åˆ›å»º32x32çš„å›¾åƒ
        img = np.ones((32, 32, 3), dtype=np.uint8) * 255
        
        if combo_id == 0:  # çº¢ç™½é»‘
            cv2.circle(img, (16, 16), 14, (0, 0, 255), 2)
            cv2.circle(img, (16, 16), 12, (255, 255, 255), -1)
            cv2.putText(img, '20', (12, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
        elif combo_id == 1:  # è“ç™½
            cv2.circle(img, (16, 16), 14, (255, 0, 0), -1)
            cv2.arrowedLine(img, (8, 16), (24, 16), (255, 255, 255), 2)
        elif combo_id == 2:  # é»„ç™½é»‘
            cv2.circle(img, (16, 16), 14, (0, 255, 255), -1)
            cv2.rectangle(img, (10, 10), (22, 22), (0, 0, 0), 2)
        elif combo_id == 3:  # çº¢ç™½
            cv2.circle(img, (16, 16), 14, (0, 0, 255), -1)
            cv2.putText(img, 'STOP', (4, 18), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 255), 1)
        elif combo_id == 4:  # é»‘ç™½
            cv2.circle(img, (16, 16), 14, (0, 0, 0), 2)
            cv2.circle(img, (16, 16), 12, (255, 255, 255), -1)
        
        test_images.append({
            'image': img.astype(np.float32) / 255.0,
            'label': combo_id,
            'name': combo['name']
        })
    
    return test_images

def load_gtsrb_samples(gtsrb_path, num_samples=5):
    """åŠ è½½GTSRBæ ·æœ¬"""
    samples = []
    
    if not os.path.exists(gtsrb_path):
        print(f"âŒ GTSRBè·¯å¾„ä¸å­˜åœ¨: {gtsrb_path}")
        return samples
    
    # ä¸ºæ¯ä¸ªé¢œè‰²ç»„åˆåŠ è½½ä¸€ä¸ªæ ·æœ¬
    for combo_id in range(5):
        combo = IMPROVED_COLOR_COMBINATIONS[combo_id]
        classes = combo['classes']
        
        # é€‰æ‹©ç¬¬ä¸€ä¸ªç±»åˆ«
        class_id = classes[0]
        class_folder = os.path.join(gtsrb_path, 'Final_Training', 'Images', f'{class_id:05d}')
        
        if os.path.exists(class_folder):
            # åŠ è½½ç¬¬ä¸€å¼ å›¾åƒ
            for img_name in os.listdir(class_folder):
                if img_name.endswith('.ppm'):
                    img_path = os.path.join(class_folder, img_name)
                    try:
                        img = Image.open(img_path).convert('RGB')
                        img = img.resize((32, 32))
                        img_array = np.array(img).astype(np.float32) / 255.0
                        
                        samples.append({
                            'image': img_array,
                            'label': combo_id,
                            'name': f"{combo['name']} (GTSRB {class_id})"
                        })
                        break
                    except:
                        continue
    
    return samples

def main():
    parser = argparse.ArgumentParser(description='ç”ŸæˆCAMå¯è§†åŒ–')
    parser.add_argument('--model_path', default='best_improved_color_combination_head.pth', 
                       help='æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--gtsrb_path', default='/home/hding22/color/GTSRB/GTSRB',
                       help='GTSRBæ•°æ®é›†è·¯å¾„')
    parser.add_argument('--output_dir', default='cam_visualizations',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--use_gtsrb', action='store_true',
                       help='ä½¿ç”¨GTSRBçœŸå®æ•°æ®')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # åˆå§‹åŒ–CAMç”Ÿæˆå™¨
    cam_generator = CAMGenerator(args.model_path)
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    if args.use_gtsrb:
        print("ğŸ“¸ åŠ è½½GTSRBçœŸå®æ ·æœ¬...")
        test_samples = load_gtsrb_samples(args.gtsrb_path)
    else:
        print("ğŸ¨ åˆ›å»ºåˆæˆæµ‹è¯•å›¾åƒ...")
        test_samples = create_test_images()
    
    print(f"âœ… å‡†å¤‡ç”Ÿæˆ {len(test_samples)} ä¸ªæ ·æœ¬çš„CAMå¯è§†åŒ–")
    
    # ç”ŸæˆCAMå¯è§†åŒ–
    for i, sample in enumerate(test_samples):
        print(f"\nğŸ¯ å¤„ç†æ ·æœ¬ {i+1}/{len(test_samples)}: {sample['name']}")
        
        # ç”ŸæˆCAM
        cam = cam_generator.generate_cam(sample['image'], sample['label'])
        
        if cam is not None:
            # ä¿å­˜è·¯å¾„
            save_path = os.path.join(args.output_dir, f'cam_{sample["name"]}.png')
            
            # å¯è§†åŒ–
            cam_generator.visualize_cam(sample['image'], cam, save_path)
            
            # ä¿å­˜åŸå§‹CAMæ•°æ®
            cam_data_path = os.path.join(args.output_dir, f'cam_{sample["name"]}.npy')
            np.save(cam_data_path, cam)
            print(f"ğŸ’¾ CAMæ•°æ®å·²ä¿å­˜: {cam_data_path}")
        else:
            print(f"âŒ æ— æ³•ä¸º {sample['name']} ç”ŸæˆCAM")
    
    print(f"\nğŸ‰ CAMå¯è§†åŒ–å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {args.output_dir}")
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    summary = {
        'model_path': args.model_path,
        'output_dir': args.output_dir,
        'num_samples': len(test_samples),
        'data_type': 'GTSRB' if args.use_gtsrb else 'Synthetic',
        'samples': [sample['name'] for sample in test_samples]
    }
    
    summary_path = os.path.join(args.output_dir, 'cam_summary.json')
    with open(summary_path, 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"ğŸ“‹ æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜: {summary_path}")

if __name__ == "__main__":
    main()
