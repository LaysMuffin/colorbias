#!/usr/bin/env python3
"""
é›†æˆé¢œè‰²æ¨ç†æ¨¡å‹CAMå¯è§†åŒ–ç”Ÿæˆå™¨ (è‹±æ–‡ç‰ˆ)
ä½¿ç”¨è®­ç»ƒå¥½çš„IntegratedColorReasoningModelç”Ÿæˆç±»åˆ«æ¿€æ´»æ˜ å°„
"""

import torch
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
import cv2
from PIL import Image, ImageDraw, ImageFont
import json
import os
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®matplotlibä¸ºè‹±æ–‡
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

class IntegratedCAMGenerator:
    """é›†æˆé¢œè‰²æ¨ç†æ¨¡å‹CAMç”Ÿæˆå™¨"""
    
    def __init__(self, model_path: str = 'best_integrated_color_model.pth'):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model_path = model_path
        self.model = None
        self.class_names = [
            'Red-White-Black (Speed Limit)',
            'Blue-White (Direction)',
            'Yellow-White-Black (Priority)',
            'Red-White (Stop)',
            'Black-White (Speed End)'
        ]
        self.color_combinations = [
            'Red-White-Black',
            'Blue-White', 
            'Yellow-White-Black',
            'Red-White',
            'Black-White'
        ]
        self.load_model()
        
    def load_model(self):
        """åŠ è½½é›†æˆé¢œè‰²æ¨ç†æ¨¡å‹"""
        try:
            from integrated_color_reasoning import IntegratedColorReasoningModel
            self.model = IntegratedColorReasoningModel(num_classes=5)
            
            # åŠ è½½é¢„è®­ç»ƒæƒé‡
            checkpoint = torch.load(self.model_path, map_location=self.device)
            # æ£€æŸ¥checkpointæ ¼å¼
            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                self.model.load_state_dict(checkpoint['model_state_dict'])
            else:
                # ç›´æ¥æ˜¯çŠ¶æ€å­—å…¸
                self.model.load_state_dict(checkpoint)
            self.model.to(self.device)
            self.model.eval()
            print(f"âœ… Loaded integrated color reasoning model from {self.model_path}")
            
        except Exception as e:
            print(f"âŒ Error loading model: {e}")
            raise
    
    def generate_test_image(self, color_combo_idx: int, size: Tuple[int, int] = (64, 64)) -> np.ndarray:
        """ç”Ÿæˆæµ‹è¯•å›¾åƒ"""
        height, width = size
        
        if color_combo_idx == 0:  # Red-White-Black
            # çº¢è‰²èƒŒæ™¯ï¼Œç™½è‰²åœ†å½¢ï¼Œé»‘è‰²æ•°å­—
            img = np.ones((height, width, 3), dtype=np.uint8) * [255, 0, 0]  # Red background
            # ç®€å•çš„å‡ ä½•å½¢çŠ¶
            img[height//4:3*height//4, width//4:3*width//4] = [255, 255, 255]  # White center
            img[height//3:2*height//3, width//3:2*width//3] = [0, 0, 0]  # Black inner
            
        elif color_combo_idx == 1:  # Blue-White
            # è“è‰²èƒŒæ™¯ï¼Œç™½è‰²ç®­å¤´
            img = np.ones((height, width, 3), dtype=np.uint8) * [0, 0, 255]  # Blue background
            # ç™½è‰²ä¸‰è§’å½¢
            img[height//4:3*height//4, width//4:3*width//4] = [255, 255, 255]  # White center
            
        elif color_combo_idx == 2:  # Yellow-White-Black
            # é»„è‰²èƒŒæ™¯ï¼Œç™½è‰²è¾¹æ¡†ï¼Œé»‘è‰²ç¬¦å·
            img = np.ones((height, width, 3), dtype=np.uint8) * [0, 255, 255]  # Yellow background
            img[10:height-10, 10:width-10] = [255, 255, 255]  # White border
            img[height//3:2*height//3, width//3:2*width//3] = [0, 0, 0]  # Black center
            
        elif color_combo_idx == 3:  # Red-White
            # çº¢è‰²èƒŒæ™¯ï¼Œç™½è‰²å…«è¾¹å½¢
            img = np.ones((height, width, 3), dtype=np.uint8) * [255, 0, 0]  # Red background
            # ç™½è‰²ä¸­å¿ƒåŒºåŸŸ
            img[height//4:3*height//4, width//4:3*width//4] = [255, 255, 255]  # White center
            
        else:  # Black-White
            # ç™½è‰²èƒŒæ™¯ï¼Œé»‘è‰²ç¬¦å·
            img = np.ones((height, width, 3), dtype=np.uint8) * 255  # White background
            img[20:height-20, 20:width-20] = [0, 0, 0]  # Black border
            img[height//2-5:height//2+5, :] = [0, 0, 0]  # Black line
            
        return img
    
    def extract_features(self, image: np.ndarray) -> torch.Tensor:
        """æå–å›¾åƒç‰¹å¾"""
        # è½¬æ¢ä¸ºtensor
        img_tensor = torch.from_numpy(image).float().permute(2, 0, 1).unsqueeze(0)
        img_tensor = img_tensor.to(self.device)
        
        # é€šè¿‡é¢œè‰²åˆ†ç±»å™¨æå–ç‰¹å¾
        with torch.no_grad():
            # è·å–é¢œè‰²åˆ†ç±»å™¨çš„ç‰¹å¾
            if hasattr(self.model.color_classifier, 'extract_color_features'):
                color_features = self.model.color_classifier.extract_color_features(img_tensor)
            else:
                # å¦‚æœæ²¡æœ‰ä¸“é—¨çš„ç‰¹å¾æå–æ–¹æ³•ï¼Œä½¿ç”¨å‰å‘ä¼ æ’­
                outputs = self.model.color_classifier(img_tensor)
                color_features = outputs['color_semantic']
            return color_features
    
    def generate_cam(self, image: np.ndarray, target_class: int) -> np.ndarray:
        """ç”ŸæˆCAMçƒ­åŠ›å›¾"""
        # è½¬æ¢ä¸ºtensor
        img_tensor = torch.from_numpy(image).float().permute(2, 0, 1).unsqueeze(0)
        img_tensor = img_tensor.to(self.device)
        img_tensor.requires_grad_(True)
        
        # è·å–ç›®æ ‡ç±»åˆ«çš„æƒé‡
        outputs = self.model(img_tensor)
        final_logits = outputs['final_logits']
        
        # è·å–ç›®æ ‡ç±»åˆ«çš„æ¢¯åº¦
        final_logits[0, target_class].backward()
        
        # è·å–è¾“å…¥å›¾åƒçš„æ¢¯åº¦
        gradients = img_tensor.grad.clone()
        img_tensor.grad.zero_()
        
        # è®¡ç®—æƒé‡
        weights = torch.mean(gradients, dim=(2, 3))
        
        # ç”ŸæˆCAM
        cam = torch.sum(weights.unsqueeze(-1).unsqueeze(-1) * img_tensor, dim=1)
        cam = F.relu(cam)  # åªä¿ç•™æ­£å€¼
        
        # å½’ä¸€åŒ–
        cam = cam - cam.min()
        cam = cam / (cam.max() + 1e-8)
        
        # è°ƒæ•´å¤§å°åˆ°åŸå§‹å›¾åƒå°ºå¯¸
        cam = F.interpolate(cam.unsqueeze(0), size=image.shape[:2], 
                          mode='bilinear', align_corners=False)
        cam = cam.squeeze().detach().cpu().numpy()
        
        return cam
    
    def create_visualization(self, image: np.ndarray, cam: np.ndarray, 
                           class_name: str, color_combo: str) -> np.ndarray:
        """åˆ›å»ºå¯è§†åŒ–å›¾åƒ"""
        # åˆ›å»ºçƒ­åŠ›å›¾
        heatmap = cv2.applyColorMap((cam * 255).astype(np.uint8), cv2.COLORMAP_JET)
        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
        
        # å åŠ åˆ°åŸå›¾
        overlay = heatmap * 0.7 + image * 0.3
        overlay = np.clip(overlay, 0, 255).astype(np.uint8)
        
        # åˆ›å»ºç»„åˆå›¾åƒ
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # åŸå§‹å›¾åƒ
        axes[0].imshow(image)
        axes[0].set_title(f'Original Image\n{color_combo}', fontsize=12, fontweight='bold')
        axes[0].axis('off')
        
        # çƒ­åŠ›å›¾
        axes[1].imshow(heatmap)
        axes[1].set_title('CAM Heatmap', fontsize=12, fontweight='bold')
        axes[1].axis('off')
        
        # å åŠ å›¾
        axes[2].imshow(overlay)
        axes[2].set_title('CAM Overlay', fontsize=12, fontweight='bold')
        axes[2].axis('off')
        
        plt.suptitle(f'Integrated Color Reasoning CAM\n{class_name}', 
                    fontsize=14, fontweight='bold')
        plt.tight_layout()
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        fig.canvas.draw()
        try:
            img_array = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
        except AttributeError:
            img_array = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)
            img_array = img_array.reshape(fig.canvas.get_width_height()[::-1] + (4,))
            img_array = img_array[:, :, :3]  # åªä¿ç•™RGBé€šé“
        else:
            img_array = img_array.reshape(fig.canvas.get_width_height()[::-1] + (3,))
        plt.close()
        
        return img_array
    
    def generate_all_cams(self, output_dir: str = 'integrated_cam_english'):
        """ä¸ºæ‰€æœ‰é¢œè‰²ç»„åˆç”ŸæˆCAM"""
        os.makedirs(output_dir, exist_ok=True)
        
        print(f"ğŸ¨ Generating CAM visualizations for integrated color reasoning model...")
        print(f"ğŸ“ Output directory: {output_dir}")
        
        results = []
        
        for i, (class_name, color_combo) in enumerate(zip(self.class_names, self.color_combinations)):
            print(f"  Processing {color_combo}...")
            
            # ç”Ÿæˆæµ‹è¯•å›¾åƒ
            image = self.generate_test_image(i)
            
            # ç”ŸæˆCAM
            cam = self.generate_cam(image, i)
            
            # åˆ›å»ºå¯è§†åŒ–
            vis_image = self.create_visualization(image, cam, class_name, color_combo)
            
            # ä¿å­˜å›¾åƒ
            output_path = os.path.join(output_dir, f'integrated_cam_{i:02d}_{color_combo.lower().replace("-", "_")}.png')
            Image.fromarray(vis_image).save(output_path)
            
            # ä¿å­˜CAMæ•°æ®
            cam_data_path = os.path.join(output_dir, f'integrated_cam_{i:02d}_{color_combo.lower().replace("-", "_")}.npy')
            np.save(cam_data_path, cam)
            
            # è®°å½•ç»“æœ
            result = {
                'class_id': i,
                'class_name': class_name,
                'color_combo': color_combo,
                'image_path': output_path,
                'cam_data_path': cam_data_path,
                'cam_max': float(cam.max()),
                'cam_mean': float(cam.mean()),
                'cam_std': float(cam.std())
            }
            results.append(result)
            
            print(f"    âœ… Saved: {output_path}")
        
        # ä¿å­˜åˆ†ææŠ¥å‘Š
        analysis_path = os.path.join(output_dir, 'integrated_cam_analysis.json')
        with open(analysis_path, 'w', encoding='utf-8') as f:
            json.dump({
                'model_info': {
                    'model_path': self.model_path,
                    'model_type': 'IntegratedColorReasoningModel',
                    'num_classes': 5
                },
                'generation_info': {
                    'total_images': len(results),
                    'output_directory': output_dir
                },
                'results': results
            }, f, indent=2, ensure_ascii=False)
        
        # åˆ›å»ºæ€»ç»“å›¾è¡¨
        self.create_summary_chart(results, output_dir)
        
        print(f"\nâœ… Generated {len(results)} CAM visualizations")
        print(f"ğŸ“Š Analysis saved to: {analysis_path}")
        
        return results
    
    def create_summary_chart(self, results: List[Dict], output_dir: str):
        """åˆ›å»ºæ€»ç»“å›¾è¡¨"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        # æå–æ•°æ®
        class_names = [r['color_combo'] for r in results]
        cam_max = [r['cam_max'] for r in results]
        cam_mean = [r['cam_mean'] for r in results]
        cam_std = [r['cam_std'] for r in results]
        
        # CAMæœ€å¤§å€¼
        bars1 = ax1.bar(range(len(class_names)), cam_max, color='skyblue', alpha=0.7)
        ax1.set_title('CAM Maximum Values', fontsize=12, fontweight='bold')
        ax1.set_ylabel('Maximum CAM Value')
        ax1.set_xticks(range(len(class_names)))
        ax1.set_xticklabels(class_names, rotation=45, ha='right')
        ax1.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars1, cam_max):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{value:.3f}', ha='center', va='bottom', fontsize=10)
        
        # CAMå¹³å‡å€¼
        bars2 = ax2.bar(range(len(class_names)), cam_mean, color='lightgreen', alpha=0.7)
        ax2.set_title('CAM Mean Values', fontsize=12, fontweight='bold')
        ax2.set_ylabel('Mean CAM Value')
        ax2.set_xticks(range(len(class_names)))
        ax2.set_xticklabels(class_names, rotation=45, ha='right')
        ax2.grid(True, alpha=0.3)
        
        for bar, value in zip(bars2, cam_mean):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                    f'{value:.3f}', ha='center', va='bottom', fontsize=10)
        
        # CAMæ ‡å‡†å·®
        bars3 = ax3.bar(range(len(class_names)), cam_std, color='salmon', alpha=0.7)
        ax3.set_title('CAM Standard Deviation', fontsize=12, fontweight='bold')
        ax3.set_ylabel('CAM Standard Deviation')
        ax3.set_xticks(range(len(class_names)))
        ax3.set_xticklabels(class_names, rotation=45, ha='right')
        ax3.grid(True, alpha=0.3)
        
        for bar, value in zip(bars3, cam_std):
            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                    f'{value:.3f}', ha='center', va='bottom', fontsize=10)
        
        # ç»¼åˆç»Ÿè®¡
        ax4.scatter(cam_mean, cam_std, s=100, c=range(len(class_names)), 
                   cmap='viridis', alpha=0.7)
        for i, name in enumerate(class_names):
            ax4.annotate(name, (cam_mean[i], cam_std[i]), 
                        xytext=(5, 5), textcoords='offset points', fontsize=9)
        ax4.set_xlabel('Mean CAM Value')
        ax4.set_ylabel('CAM Standard Deviation')
        ax4.set_title('CAM Statistics Overview', fontsize=12, fontweight='bold')
        ax4.grid(True, alpha=0.3)
        
        plt.suptitle('Integrated Color Reasoning CAM Analysis Summary', 
                    fontsize=16, fontweight='bold')
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        summary_path = os.path.join(output_dir, 'integrated_cam_summary.png')
        plt.savefig(summary_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“Š Summary chart saved to: {summary_path}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¨ Integrated Color Reasoning CAM Generator (English)")
    print("=" * 60)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = 'best_integrated_color_model.pth'
    if not os.path.exists(model_path):
        print(f"âŒ Model file not found: {model_path}")
        print("Please run integrated_color_reasoning.py first to train the model.")
        return
    
    try:
        # åˆ›å»ºCAMç”Ÿæˆå™¨
        generator = IntegratedCAMGenerator(model_path)
        
        # ç”Ÿæˆæ‰€æœ‰CAM
        results = generator.generate_all_cams()
        
        print("\nğŸ‰ CAM generation completed successfully!")
        print(f"ğŸ“ Check the 'integrated_cam_english' directory for results")
        
    except Exception as e:
        print(f"âŒ Error during CAM generation: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
