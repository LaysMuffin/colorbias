#!/usr/bin/env python3
"""
é›†æˆé¢œè‰²æ¨ç†æ¨¡å‹çœŸå®GTSRB CAMå¯è§†åŒ–ç”Ÿæˆå™¨ (è‹±æ–‡ç‰ˆ)
ä½¿ç”¨çœŸå®GTSRBäº¤é€šæ ‡å¿—å›¾åƒç”Ÿæˆç±»åˆ«æ¿€æ´»æ˜ å°„
"""

import torch
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
import cv2
from PIL import Image, ImageDraw, ImageFont
import json
import os
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®matplotlibä¸ºè‹±æ–‡
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

class IntegratedRealGTSRBCAMGenerator:
    """é›†æˆé¢œè‰²æ¨ç†æ¨¡å‹çœŸå®GTSRB CAMç”Ÿæˆå™¨"""
    
    def __init__(self, model_path: str = 'best_integrated_color_model.pth'):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model_path = model_path
        self.model = None
        self.class_names = [
            'Red-White-Black (Speed Limit)',
            'Blue-White (Direction)',
            'Yellow-White-Black (Priority)',
            'Red-White (Stop)',
            'Black-White (Speed End)'
        ]
        self.color_combinations = [
            'Red-White-Black',
            'Blue-White', 
            'Yellow-White-Black',
            'Red-White',
            'Black-White'
        ]
        # GTSRBç±»åˆ«åˆ°é¢œè‰²ç»„åˆçš„æ˜ å°„
        self.gtsrb_to_color_combo = {
            0: 0,  # Speed limit 20 - Red-White-Black
            1: 0,  # Speed limit 30 - Red-White-Black
            2: 0,  # Speed limit 50 - Red-White-Black
            33: 1, # Turn right ahead - Blue-White
            34: 1, # Turn left ahead - Blue-White
            35: 1, # Ahead only - Blue-White
            12: 2, # Priority road - Yellow-White-Black
            32: 2, # End of all speed and passing limits - Yellow-White-Black
            41: 2, # End of no passing - Yellow-White-Black
            14: 3, # Stop - Red-White
            6: 4,  # End of speed limit (80) - Black-White
        }
        self.load_model()
        
    def load_model(self):
        """åŠ è½½é›†æˆé¢œè‰²æ¨ç†æ¨¡å‹"""
        try:
            from integrated_color_reasoning import IntegratedColorReasoningModel
            self.model = IntegratedColorReasoningModel(num_classes=5)
            
            # åŠ è½½é¢„è®­ç»ƒæƒé‡
            checkpoint = torch.load(self.model_path, map_location=self.device)
            # æ£€æŸ¥checkpointæ ¼å¼
            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                self.model.load_state_dict(checkpoint['model_state_dict'])
            else:
                # ç›´æ¥æ˜¯çŠ¶æ€å­—å…¸
                self.model.load_state_dict(checkpoint)
            self.model.to(self.device)
            self.model.eval()
            print(f"âœ… Loaded integrated color reasoning model from {self.model_path}")
            
        except Exception as e:
            print(f"âŒ Error loading model: {e}")
            raise
    
    def load_gtsrb_samples(self) -> Dict[int, List[np.ndarray]]:
        """åŠ è½½çœŸå®GTSRBæ ·æœ¬"""
        samples = {i: [] for i in range(5)}  # 5ä¸ªé¢œè‰²ç»„åˆ
        
        # GTSRBæ•°æ®é›†è·¯å¾„
        gtsrb_path = "/home/hding22/color/GTSRB/GTSRB/Final_Training/Images"
        if not os.path.exists(gtsrb_path):
            print(f"âš ï¸ GTSRB dataset not found at {gtsrb_path}")
            print("Using synthetic images instead...")
            return self.generate_synthetic_samples()
        
        print(f"ğŸ“ Loading real GTSRB samples from {gtsrb_path}")
        
        # éå†GTSRBç±»åˆ«
        for gtsrb_class, color_combo in self.gtsrb_to_color_combo.items():
            class_path = os.path.join(gtsrb_path, f"{gtsrb_class:05d}")
            if not os.path.exists(class_path):
                continue
                
            # åŠ è½½è¯¥ç±»åˆ«çš„å‰3å¼ å›¾åƒ
            image_files = [f for f in os.listdir(class_path) if f.endswith('.ppm')][:3]
            
            for img_file in image_files:
                img_path = os.path.join(class_path, img_file)
                try:
                    # åŠ è½½å›¾åƒ
                    img = cv2.imread(img_path)
                    if img is not None:
                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                        # è°ƒæ•´å¤§å°åˆ°64x64
                        img = cv2.resize(img, (64, 64))
                        samples[color_combo].append(img)
                except Exception as e:
                    print(f"âš ï¸ Error loading {img_path}: {e}")
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸåŠ è½½äº†è¶³å¤Ÿçš„æ ·æœ¬
        total_samples = sum(len(samples[i]) for i in range(5))
        if total_samples < 10:
            print(f"âš ï¸ Only loaded {total_samples} samples, using synthetic images...")
            return self.generate_synthetic_samples()
        
        print(f"âœ… Loaded {total_samples} real GTSRB samples")
        return samples
    
    def generate_synthetic_samples(self) -> Dict[int, List[np.ndarray]]:
        """ç”Ÿæˆåˆæˆæ ·æœ¬ä½œä¸ºå¤‡é€‰"""
        samples = {i: [] for i in range(5)}
        
        for i in range(5):
            for j in range(3):  # æ¯ä¸ªç»„åˆç”Ÿæˆ3ä¸ªæ ·æœ¬
                img = self.generate_synthetic_image(i)
                samples[i].append(img)
        
        print(f"âœ… Generated {sum(len(samples[i]) for i in range(5))} synthetic samples")
        return samples
    
    def generate_synthetic_image(self, color_combo_idx: int, size: Tuple[int, int] = (64, 64)) -> np.ndarray:
        """ç”Ÿæˆåˆæˆæµ‹è¯•å›¾åƒ"""
        height, width = size
        
        if color_combo_idx == 0:  # Red-White-Black
            img = np.ones((height, width, 3), dtype=np.uint8) * [255, 0, 0]  # Red background
            img[height//4:3*height//4, width//4:3*width//4] = [255, 255, 255]  # White center
            img[height//3:2*height//3, width//3:2*width//3] = [0, 0, 0]  # Black inner
            
        elif color_combo_idx == 1:  # Blue-White
            img = np.ones((height, width, 3), dtype=np.uint8) * [0, 0, 255]  # Blue background
            img[height//4:3*height//4, width//4:3*width//4] = [255, 255, 255]  # White center
            
        elif color_combo_idx == 2:  # Yellow-White-Black
            img = np.ones((height, width, 3), dtype=np.uint8) * [0, 255, 255]  # Yellow background
            img[10:height-10, 10:width-10] = [255, 255, 255]  # White border
            img[height//3:2*height//3, width//3:2*width//3] = [0, 0, 0]  # Black center
            
        elif color_combo_idx == 3:  # Red-White
            img = np.ones((height, width, 3), dtype=np.uint8) * [255, 0, 0]  # Red background
            img[height//4:3*height//4, width//4:3*width//4] = [255, 255, 255]  # White center
            
        else:  # Black-White
            img = np.ones((height, width, 3), dtype=np.uint8) * 255  # White background
            img[20:height-20, 20:width-20] = [0, 0, 0]  # Black border
            img[height//2-5:height//2+5, :] = [0, 0, 0]  # Black line
            
        return img
    
    def generate_cam(self, image: np.ndarray, target_class: int) -> np.ndarray:
        """ç”ŸæˆCAMçƒ­åŠ›å›¾"""
        # è½¬æ¢ä¸ºtensor
        img_tensor = torch.from_numpy(image).float().permute(2, 0, 1).unsqueeze(0)
        img_tensor = img_tensor.to(self.device)
        img_tensor.requires_grad_(True)
        
        # è·å–ç›®æ ‡ç±»åˆ«çš„æƒé‡
        outputs = self.model(img_tensor)
        final_logits = outputs['final_logits']
        
        # è·å–ç›®æ ‡ç±»åˆ«çš„æ¢¯åº¦
        final_logits[0, target_class].backward()
        
        # è·å–è¾“å…¥å›¾åƒçš„æ¢¯åº¦
        gradients = img_tensor.grad.clone()
        img_tensor.grad.zero_()
        
        # è®¡ç®—æƒé‡
        weights = torch.mean(gradients, dim=(2, 3))
        
        # ç”ŸæˆCAM
        cam = torch.sum(weights.unsqueeze(-1).unsqueeze(-1) * img_tensor, dim=1)
        cam = F.relu(cam)  # åªä¿ç•™æ­£å€¼
        
        # å½’ä¸€åŒ–
        cam = cam - cam.min()
        cam = cam / (cam.max() + 1e-8)
        
        # è°ƒæ•´å¤§å°åˆ°åŸå§‹å›¾åƒå°ºå¯¸
        cam = F.interpolate(cam.unsqueeze(0), size=image.shape[:2], 
                          mode='bilinear', align_corners=False)
        cam = cam.squeeze().detach().cpu().numpy()
        
        return cam
    
    def create_visualization(self, image: np.ndarray, cam: np.ndarray, 
                           class_name: str, color_combo: str, sample_idx: int) -> np.ndarray:
        """åˆ›å»ºå¯è§†åŒ–å›¾åƒ"""
        # åˆ›å»ºçƒ­åŠ›å›¾
        heatmap = cv2.applyColorMap((cam * 255).astype(np.uint8), cv2.COLORMAP_JET)
        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
        
        # å åŠ åˆ°åŸå›¾
        overlay = heatmap * 0.7 + image * 0.3
        overlay = np.clip(overlay, 0, 255).astype(np.uint8)
        
        # åˆ›å»ºç»„åˆå›¾åƒ
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # åŸå§‹å›¾åƒ
        axes[0].imshow(image)
        axes[0].set_title(f'Real GTSRB Image\n{color_combo} (Sample {sample_idx+1})', 
                         fontsize=12, fontweight='bold')
        axes[0].axis('off')
        
        # çƒ­åŠ›å›¾
        axes[1].imshow(heatmap)
        axes[1].set_title('CAM Heatmap', fontsize=12, fontweight='bold')
        axes[1].axis('off')
        
        # å åŠ å›¾
        axes[2].imshow(overlay)
        axes[2].set_title('CAM Overlay', fontsize=12, fontweight='bold')
        axes[2].axis('off')
        
        plt.suptitle(f'Integrated Color Reasoning CAM - Real GTSRB\n{class_name}', 
                    fontsize=14, fontweight='bold')
        plt.tight_layout()
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        fig.canvas.draw()
        try:
            img_array = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
        except AttributeError:
            img_array = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)
            img_array = img_array.reshape(fig.canvas.get_width_height()[::-1] + (4,))
            img_array = img_array[:, :, :3]  # åªä¿ç•™RGBé€šé“
        else:
            img_array = img_array.reshape(fig.canvas.get_width_height()[::-1] + (3,))
        plt.close()
        
        return img_array
    
    def generate_all_cams(self, output_dir: str = 'integrated_cam_real_gtsrb'):
        """ä¸ºæ‰€æœ‰çœŸå®GTSRBæ ·æœ¬ç”ŸæˆCAM"""
        os.makedirs(output_dir, exist_ok=True)
        
        print(f"ğŸ¨ Generating CAM visualizations for integrated color reasoning model with real GTSRB images...")
        print(f"ğŸ“ Output directory: {output_dir}")
        
        # åŠ è½½çœŸå®GTSRBæ ·æœ¬
        samples = self.load_gtsrb_samples()
        
        results = []
        
        for color_combo_idx, (class_name, color_combo) in enumerate(zip(self.class_names, self.color_combinations)):
            print(f"  Processing {color_combo}...")
            
            if color_combo_idx not in samples or len(samples[color_combo_idx]) == 0:
                print(f"    âš ï¸ No samples for {color_combo}")
                continue
            
            for sample_idx, image in enumerate(samples[color_combo_idx]):
                print(f"    Processing sample {sample_idx+1}/{len(samples[color_combo_idx])}...")
                
                # ç”ŸæˆCAM
                cam = self.generate_cam(image, color_combo_idx)
                
                # åˆ›å»ºå¯è§†åŒ–
                vis_image = self.create_visualization(image, cam, class_name, color_combo, sample_idx)
                
                # ä¿å­˜å›¾åƒ
                output_path = os.path.join(output_dir, 
                    f'integrated_cam_{color_combo_idx:02d}_{color_combo.lower().replace("-", "_")}_sample_{sample_idx+1}.png')
                Image.fromarray(vis_image).save(output_path)
                
                # ä¿å­˜CAMæ•°æ®
                cam_data_path = os.path.join(output_dir, 
                    f'integrated_cam_{color_combo_idx:02d}_{color_combo.lower().replace("-", "_")}_sample_{sample_idx+1}.npy')
                np.save(cam_data_path, cam)
                
                # è®°å½•ç»“æœ
                result = {
                    'class_id': color_combo_idx,
                    'class_name': class_name,
                    'color_combo': color_combo,
                    'sample_idx': sample_idx + 1,
                    'image_path': output_path,
                    'cam_data_path': cam_data_path,
                    'cam_max': float(cam.max()),
                    'cam_mean': float(cam.mean()),
                    'cam_std': float(cam.std()),
                    'is_real_gtsrb': True
                }
                results.append(result)
                
                print(f"      âœ… Saved: {output_path}")
        
        # ä¿å­˜åˆ†ææŠ¥å‘Š
        analysis_path = os.path.join(output_dir, 'integrated_cam_real_gtsrb_analysis.json')
        with open(analysis_path, 'w', encoding='utf-8') as f:
            json.dump({
                'model_info': {
                    'model_path': self.model_path,
                    'model_type': 'IntegratedColorReasoningModel',
                    'num_classes': 5
                },
                'generation_info': {
                    'total_images': len(results),
                    'output_directory': output_dir,
                    'data_source': 'Real GTSRB' if any(r['is_real_gtsrb'] for r in results) else 'Synthetic'
                },
                'results': results
            }, f, indent=2, ensure_ascii=False)
        
        # åˆ›å»ºæ€»ç»“å›¾è¡¨
        self.create_summary_chart(results, output_dir)
        
        print(f"\nâœ… Generated {len(results)} CAM visualizations")
        print(f"ğŸ“Š Analysis saved to: {analysis_path}")
        
        return results
    
    def create_summary_chart(self, results: List[Dict], output_dir: str):
        """åˆ›å»ºæ€»ç»“å›¾è¡¨"""
        if not results:
            return
            
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        # æŒ‰é¢œè‰²ç»„åˆåˆ†ç»„
        color_combo_stats = {}
        for result in results:
            combo = result['color_combo']
            if combo not in color_combo_stats:
                color_combo_stats[combo] = {'max': [], 'mean': [], 'std': []}
            color_combo_stats[combo]['max'].append(result['cam_max'])
            color_combo_stats[combo]['mean'].append(result['cam_mean'])
            color_combo_stats[combo]['std'].append(result['cam_std'])
        
        # è®¡ç®—å¹³å‡å€¼
        class_names = list(color_combo_stats.keys())
        cam_max_avg = [np.mean(color_combo_stats[combo]['max']) for combo in class_names]
        cam_mean_avg = [np.mean(color_combo_stats[combo]['mean']) for combo in class_names]
        cam_std_avg = [np.mean(color_combo_stats[combo]['std']) for combo in class_names]
        
        # CAMæœ€å¤§å€¼
        bars1 = ax1.bar(range(len(class_names)), cam_max_avg, color='skyblue', alpha=0.7)
        ax1.set_title('CAM Maximum Values (Average)', fontsize=12, fontweight='bold')
        ax1.set_ylabel('Maximum CAM Value')
        ax1.set_xticks(range(len(class_names)))
        ax1.set_xticklabels(class_names, rotation=45, ha='right')
        ax1.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars1, cam_max_avg):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{value:.3f}', ha='center', va='bottom', fontsize=10)
        
        # CAMå¹³å‡å€¼
        bars2 = ax2.bar(range(len(class_names)), cam_mean_avg, color='lightgreen', alpha=0.7)
        ax2.set_title('CAM Mean Values (Average)', fontsize=12, fontweight='bold')
        ax2.set_ylabel('Mean CAM Value')
        ax2.set_xticks(range(len(class_names)))
        ax2.set_xticklabels(class_names, rotation=45, ha='right')
        ax2.grid(True, alpha=0.3)
        
        for bar, value in zip(bars2, cam_mean_avg):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                    f'{value:.3f}', ha='center', va='bottom', fontsize=10)
        
        # CAMæ ‡å‡†å·®
        bars3 = ax3.bar(range(len(class_names)), cam_std_avg, color='salmon', alpha=0.7)
        ax3.set_title('CAM Standard Deviation (Average)', fontsize=12, fontweight='bold')
        ax3.set_ylabel('CAM Standard Deviation')
        ax3.set_xticks(range(len(class_names)))
        ax3.set_xticklabels(class_names, rotation=45, ha='right')
        ax3.grid(True, alpha=0.3)
        
        for bar, value in zip(bars3, cam_std_avg):
            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                    f'{value:.3f}', ha='center', va='bottom', fontsize=10)
        
        # ç»¼åˆç»Ÿè®¡
        ax4.scatter(cam_mean_avg, cam_std_avg, s=100, c=range(len(class_names)), 
                   cmap='viridis', alpha=0.7)
        for i, name in enumerate(class_names):
            ax4.annotate(name, (cam_mean_avg[i], cam_std_avg[i]), 
                        xytext=(5, 5), textcoords='offset points', fontsize=9)
        ax4.set_xlabel('Mean CAM Value')
        ax4.set_ylabel('CAM Standard Deviation')
        ax4.set_title('CAM Statistics Overview', fontsize=12, fontweight='bold')
        ax4.grid(True, alpha=0.3)
        
        plt.suptitle('Integrated Color Reasoning CAM Analysis - Real GTSRB Images', 
                    fontsize=16, fontweight='bold')
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        summary_path = os.path.join(output_dir, 'integrated_cam_real_gtsrb_summary.png')
        plt.savefig(summary_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“Š Summary chart saved to: {summary_path}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¨ Integrated Color Reasoning CAM Generator - Real GTSRB (English)")
    print("=" * 70)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = 'best_integrated_color_model.pth'
    if not os.path.exists(model_path):
        print(f"âŒ Model file not found: {model_path}")
        print("Please run integrated_color_reasoning.py first to train the model.")
        return
    
    try:
        # åˆ›å»ºCAMç”Ÿæˆå™¨
        generator = IntegratedRealGTSRBCAMGenerator(model_path)
        
        # ç”Ÿæˆæ‰€æœ‰CAM
        results = generator.generate_all_cams()
        
        print("\nğŸ‰ CAM generation completed successfully!")
        print(f"ğŸ“ Check the 'integrated_cam_real_gtsrb' directory for results")
        
    except Exception as e:
        print(f"âŒ Error during CAM generation: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
