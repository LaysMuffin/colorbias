# model_architecture_analysis.py
# è¯¦ç»†åˆ†ææˆ‘ä»¬å½“å‰æ¨¡å‹çš„æ¶æ„

import torch
import torch.nn as nn
import json
import sys
import os

def analyze_model_architecture():
    """åˆ†ææ¨¡å‹æ¶æ„"""
    print("ğŸ” æ¨¡å‹æ¶æ„è¯¦ç»†åˆ†æ")
    print("="*80)
    
    # æ¨¡å‹1: ä¿®å¤çš„é¢œè‰²å¤´
    class FixedColorHead(nn.Module):
        def __init__(self, input_dim=64, num_classes=43):
            super().__init__()
            self.input_dim = input_dim
            self.num_classes = num_classes
            
            # é¢œè‰²ç‰¹å¾æå–å™¨
            self.color_extractor = nn.Sequential(
                nn.Linear(input_dim, 256),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(256, 128),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(128, 64),
                nn.ReLU()
            )
            
            # é¢œè‰²åˆ†ç±»å™¨
            self.color_classifier = nn.Sequential(
                nn.Linear(64, 128),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(128, 64),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(64, num_classes)
            )
            
            self._initialize_weights()
        
        def _initialize_weights(self):
            for m in self.modules():
                if isinstance(m, nn.Linear):
                    nn.init.xavier_uniform_(m.weight)
                    if m.bias is not None:
                        nn.init.constant_(m.bias, 0)
        
        def forward(self, x):
            # é¢œè‰²ç‰¹å¾æå–
            color_features = self.color_extractor(x)
            
            # é¢œè‰²è¯­ä¹‰é¢„æµ‹
            color_logits = self.color_classifier(color_features)
            
            return {
                'color_semantic_logits': color_logits,
                'color_features': color_features,
                'features': x
            }
    
    # æ¨¡å‹2: åŸºç¡€æ¨¡å‹
    class BaseModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.features = nn.Sequential(
                nn.Linear(3072, 1024),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(1024, 512),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(512, 256),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(256, 128),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(128, 43)
            )
            
            self._initialize_weights()
        
        def _initialize_weights(self):
            for m in self.modules():
                if isinstance(m, nn.Linear):
                    nn.init.xavier_uniform_(m.weight)
                    if m.bias is not None:
                        nn.init.constant_(m.bias, 0)
        
        def forward(self, x):
            x = x.view(x.size(0), -1)
            return {'logits': self.features(x)}
    
    # æ¨¡å‹3: é›†æˆæ¨¡å‹
    class EnsembleModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.base_model = BaseModel()
            self.color_head = FixedColorHead()
            
            # å¯å­¦ä¹ çš„èåˆæƒé‡
            self.fusion_weight = nn.Parameter(torch.tensor(0.5))
            
        def forward(self, x):
            # åŸºç¡€æ¨¡å‹é¢„æµ‹
            base_outputs = self.base_model(x)
            base_logits = base_outputs['logits']
            
            # é¢œè‰²å¤´é¢„æµ‹
            features = x.view(x.size(0), -1)[:, :64]
            color_outputs = self.color_head(features)
            color_logits = color_outputs['color_semantic_logits']
            
            # èåˆé¢„æµ‹
            fusion_weight = torch.sigmoid(self.fusion_weight)
            final_logits = fusion_weight * base_logits + (1 - fusion_weight) * color_logits
            
            return {
                'final_logits': final_logits,
                'base_logits': base_logits,
                'color_logits': color_logits,
                'fusion_weight': fusion_weight
            }
    
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    fixed_color_head = FixedColorHead()
    base_model = BaseModel()
    ensemble_model = EnsembleModel()
    
    # åˆ†ææ¯ä¸ªæ¨¡å‹
    models = {
        'FixedColorHead': fixed_color_head,
        'BaseModel': base_model,
        'EnsembleModel': ensemble_model
    }
    
    architecture_details = {}
    
    for model_name, model in models.items():
        print(f"\nğŸ”¬ {model_name} æ¶æ„åˆ†æ")
        print("-" * 60)
        
        # è®¡ç®—å‚æ•°æ•°é‡
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"æ€»å‚æ•°é‡: {total_params:,}")
        print(f"å¯è®­ç»ƒå‚æ•°é‡: {trainable_params:,}")
        
        # è¯¦ç»†å±‚åˆ†æ
        layer_details = []
        for name, module in model.named_modules():
            if len(list(module.children())) == 0:  # å¶å­èŠ‚ç‚¹
                if isinstance(module, nn.Linear):
                    layer_details.append({
                        'name': name,
                        'type': 'Linear',
                        'in_features': module.in_features,
                        'out_features': module.out_features,
                        'parameters': module.weight.numel() + module.bias.numel()
                    })
                elif isinstance(module, nn.Dropout):
                    layer_details.append({
                        'name': name,
                        'type': 'Dropout',
                        'p': module.p,
                        'parameters': 0
                    })
                elif isinstance(module, nn.ReLU):
                    layer_details.append({
                        'name': name,
                        'type': 'ReLU',
                        'parameters': 0
                    })
                elif isinstance(module, nn.Parameter):
                    layer_details.append({
                        'name': name,
                        'type': 'Parameter',
                        'shape': list(module.shape),
                        'parameters': module.numel()
                    })
        
        print(f"\nè¯¦ç»†å±‚ç»“æ„:")
        for layer in layer_details:
            if layer['type'] == 'Linear':
                print(f"  {layer['name']}: Linear({layer['in_features']} -> {layer['out_features']}) - {layer['parameters']:,} å‚æ•°")
            elif layer['type'] == 'Dropout':
                print(f"  {layer['name']}: Dropout(p={layer['p']})")
            elif layer['type'] == 'ReLU':
                print(f"  {layer['name']}: ReLU()")
            elif layer['type'] == 'Parameter':
                print(f"  {layer['name']}: Parameter{layer['shape']} - {layer['parameters']:,} å‚æ•°")
        
        # è®¡ç®—FLOPsï¼ˆç®€åŒ–ä¼°ç®—ï¼‰
        if model_name == 'FixedColorHead':
            # 64 -> 256 -> 128 -> 64 -> 128 -> 64 -> 43
            flops = 64*256 + 256*128 + 128*64 + 64*128 + 128*64 + 64*43
        elif model_name == 'BaseModel':
            # 3072 -> 1024 -> 512 -> 256 -> 128 -> 43
            flops = 3072*1024 + 1024*512 + 512*256 + 256*128 + 128*43
        else:  # EnsembleModel
            # åŸºç¡€æ¨¡å‹ + é¢œè‰²å¤´ + èåˆ
            base_flops = 3072*1024 + 1024*512 + 512*256 + 256*128 + 128*43
            color_flops = 64*256 + 256*128 + 128*64 + 64*128 + 128*64 + 64*43
            flops = base_flops + color_flops + 43*2  # èåˆæ“ä½œ
        
        print(f"\nä¼°ç®—FLOPs: {flops:,}")
        
        # å†…å­˜ä½¿ç”¨ä¼°ç®—ï¼ˆMBï¼‰
        memory_mb = total_params * 4 / (1024 * 1024)  # å‡è®¾float32
        print(f"å†…å­˜ä½¿ç”¨ä¼°ç®—: {memory_mb:.2f} MB")
        
        architecture_details[model_name] = {
            'total_params': total_params,
            'trainable_params': trainable_params,
            'flops': flops,
            'memory_mb': memory_mb,
            'layers': layer_details
        }
    
    # æ¶æ„å¯¹æ¯”æ€»ç»“
    print(f"\nğŸ“Š æ¶æ„å¯¹æ¯”æ€»ç»“")
    print("="*80)
    
    print(f"{'æ¨¡å‹':<15} {'å‚æ•°é‡':<12} {'FLOPs':<15} {'å†…å­˜(MB)':<10} {'æ€§èƒ½(%)':<10}")
    print("-" * 80)
    
    # ä»æµ‹è¯•ç»“æœä¸­è·å–æ€§èƒ½æ•°æ®
    performance_data = {
        'FixedColorHead': 12.24,
        'BaseModel': 74.10,
        'EnsembleModel': 77.01
    }
    
    for model_name in models.keys():
        details = architecture_details[model_name]
        performance = performance_data.get(model_name, 0.0)
        print(f"{model_name:<15} {details['total_params']:<12,} {details['flops']:<15,} {details['memory_mb']:<10.2f} {performance:<10.2f}")
    
    # æ¶æ„ç‰¹ç‚¹åˆ†æ
    print(f"\nğŸ¯ æ¶æ„ç‰¹ç‚¹åˆ†æ")
    print("="*60)
    
    print(f"1. ä¿®å¤é¢œè‰²å¤´ (FixedColorHead):")
    print(f"   - è¾“å…¥: 64ç»´ç‰¹å¾ (å›¾åƒå‰64ä¸ªåƒç´ )")
    print(f"   - ç»“æ„: 64->256->128->64->128->64->43")
    print(f"   - ç‰¹ç‚¹: è½»é‡çº§ï¼Œä¸“æ³¨äºé¢œè‰²è¯­ä¹‰å­¦ä¹ ")
    print(f"   - æ€§èƒ½: 12.24% (å•ç‹¬ä½¿ç”¨æ•ˆæœæœ‰é™)")
    
    print(f"\n2. åŸºç¡€æ¨¡å‹ (BaseModel):")
    print(f"   - è¾“å…¥: 3072ç»´ç‰¹å¾ (32x32x3å›¾åƒ)")
    print(f"   - ç»“æ„: 3072->1024->512->256->128->43")
    print(f"   - ç‰¹ç‚¹: æ ‡å‡†å…¨è¿æ¥ç½‘ç»œï¼Œå¤„ç†å®Œæ•´å›¾åƒä¿¡æ¯")
    print(f"   - æ€§èƒ½: 74.10% (åŸºç¡€åˆ†ç±»èƒ½åŠ›å¼º)")
    
    print(f"\n3. é›†æˆæ¨¡å‹ (EnsembleModel):")
    print(f"   - èåˆç­–ç•¥: å¯å­¦ä¹ æƒé‡èåˆ")
    print(f"   - èåˆå…¬å¼: final = w*base + (1-w)*color")
    print(f"   - ç‰¹ç‚¹: ç»“åˆåŸºç¡€åˆ†ç±»å’Œé¢œè‰²è¯­ä¹‰")
    print(f"   - æ€§èƒ½: 77.01% (æœ€ä½³æ€§èƒ½)")
    
    # è®¾è®¡ä¼˜åŠ¿åˆ†æ
    print(f"\nâœ… è®¾è®¡ä¼˜åŠ¿")
    print("="*60)
    
    print(f"1. æ¨¡å—åŒ–è®¾è®¡:")
    print(f"   - é¢œè‰²å¤´å’ŒåŸºç¡€æ¨¡å‹å¯ç‹¬ç«‹è®­ç»ƒ")
    print(f"   - ä¾¿äºè°ƒè¯•å’Œä¼˜åŒ–")
    print(f"   - æ”¯æŒä¸åŒçš„èåˆç­–ç•¥")
    
    print(f"\n2. è½»é‡çº§é¢œè‰²å¤´:")
    print(f"   - å‚æ•°é‡å°‘ (çº¦50Kå‚æ•°)")
    print(f"   - è®¡ç®—æ•ˆç‡é«˜")
    print(f"   - ä¸“æ³¨äºé¢œè‰²ç‰¹å¾å­¦ä¹ ")
    
    print(f"\n3. å¯å­¦ä¹ èåˆ:")
    print(f"   - è‡ªåŠ¨å­¦ä¹ æœ€ä¼˜èåˆæƒé‡")
    print(f"   - é€‚åº”ä¸åŒæ•°æ®åˆ†å¸ƒ")
    print(f"   - é¿å…æ‰‹åŠ¨è°ƒå‚")
    
    print(f"\n4. ä¿®å¤æˆåŠŸ:")
    print(f"   - è§£å†³äº†è´ŸæŸå¤±é—®é¢˜")
    print(f"   - è®­ç»ƒç¨³å®šæ€§å¥½")
    print(f"   - åœ¨çœŸå®æ•°æ®ä¸ŠéªŒè¯æœ‰æ•ˆ")
    
    # ä¿å­˜æ¶æ„è¯¦æƒ…
    with open("model_architecture_details.json", 'w') as f:
        json.dump(architecture_details, f, indent=2, default=str)
    
    print(f"\nğŸ’¾ æ¶æ„è¯¦æƒ…å·²ä¿å­˜åˆ°: model_architecture_details.json")
    print("ğŸ‰ æ¶æ„åˆ†æå®Œæˆ!")
    
    return architecture_details

if __name__ == '__main__':
    analyze_model_architecture()

