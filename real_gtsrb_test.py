# real_gtsrb_test.py
# åœ¨çœŸå®GTSRBæ•°æ®é›†ä¸Šæµ‹è¯•ä¿®å¤åçš„é¢œè‰²å¤´

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import time
import json
import sys
import os
import numpy as np
from PIL import Image
import torchvision.transforms as transforms
from sklearn.model_selection import train_test_split
import pandas as pd

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
sys.path.append('/home/hding22/gtsrb_color_project/color_bias')

def download_gtsrb_data(data_root='/home/hding22/gtsrb_color_project/data'):
    """ä¸‹è½½GTSRBæ•°æ®é›†"""
    import urllib.request
    import zipfile
    
    gtsrb_dir = os.path.join(data_root, 'GTSRB')
    
    if os.path.exists(gtsrb_dir):
        print(f"GTSRBæ•°æ®é›†å·²å­˜åœ¨äº {gtsrb_dir}")
        return gtsrb_dir
    
    print("ä¸‹è½½GTSRBæ•°æ®é›†...")
    os.makedirs(data_root, exist_ok=True)
    
    # ä¸‹è½½URL
    url = "https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip"
    zip_path = os.path.join(data_root, "GTSRB_Final_Training_Images.zip")
    
    try:
        urllib.request.urlretrieve(url, zip_path)
        print("ä¸‹è½½å®Œæˆ!")
    except Exception as e:
        print(f"ä¸‹è½½å¤±è´¥: {e}")
        return None
    
    # è§£å‹
    print("è§£å‹æ•°æ®é›†...")
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(data_root)
    
    # æ¸…ç†
    os.remove(zip_path)
    print("æ•°æ®é›†å‡†å¤‡å®Œæˆ!")
    return gtsrb_dir

class GTSRBDataset(torch.utils.data.Dataset):
    """ç®€åŒ–çš„GTSRBæ•°æ®é›†"""
    
    def __init__(self, data_root, split='train', img_size=32, transform=None):
        self.data_root = data_root
        self.split = split
        self.img_size = img_size
        
        if transform is None:
            if split == 'train':
                self.transform = transforms.Compose([
                    transforms.Resize((img_size + 4, img_size + 4)),
                    transforms.RandomCrop(img_size),
                    transforms.RandomHorizontalFlip(p=0.1),
                    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
                ])
            else:
                self.transform = transforms.Compose([
                    transforms.Resize((img_size, img_size)),
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
                ])
        else:
            self.transform = transform
        
        self.data, self.labels = self._load_data()
        
        # åˆ†å‰²æ•°æ®
        if split in ['train', 'val']:
            train_data, val_data, train_labels, val_labels = train_test_split(
                self.data, self.labels, test_size=0.2, random_state=42, stratify=self.labels
            )
            if split == 'train':
                self.data, self.labels = train_data, train_labels
            else:
                self.data, self.labels = val_data, val_labels
    
    def _load_data(self):
        """åŠ è½½å›¾åƒè·¯å¾„å’Œæ ‡ç­¾"""
        images_dir = os.path.join(self.data_root, 'Final_Training', 'Images')
        
        if not os.path.exists(images_dir):
            raise FileNotFoundError(f"å›¾åƒç›®å½•æœªæ‰¾åˆ°: {images_dir}")
        
        data = []
        labels = []
        
        # åŠ è½½è®­ç»ƒæ•°æ®ï¼ˆç±»åˆ«ç›®å½•ï¼‰
        for class_id in range(43):
            class_dir = os.path.join(images_dir, f'{class_id:05d}')
            
            if os.path.exists(class_dir):
                # è¯»å–CSVæ–‡ä»¶
                csv_file = os.path.join(class_dir, f'GT-{class_id:05d}.csv')
                
                if os.path.exists(csv_file):
                    df = pd.read_csv(csv_file, delimiter=';')
                    
                    for _, row in df.iterrows():
                        img_file = row['Filename']
                        img_path = os.path.join(class_dir, img_file)
                        
                        if os.path.exists(img_path):
                            data.append(img_path)
                            labels.append(class_id)
                else:
                    # å¤‡ç”¨æ–¹æ¡ˆï¼šåŠ è½½æ‰€æœ‰.ppmæ–‡ä»¶
                    for file in os.listdir(class_dir):
                        if file.endswith('.ppm'):
                            img_path = os.path.join(class_dir, file)
                            data.append(img_path)
                            labels.append(class_id)
        
        print(f"åŠ è½½äº† {len(data)} å¼ å›¾åƒï¼Œå…± {len(set(labels))} ä¸ªç±»åˆ«")
        return data, labels
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        img_path = self.data[idx]
        label = self.labels[idx]
        
        # åŠ è½½å’Œè½¬æ¢å›¾åƒ
        image = Image.open(img_path).convert('RGB')
        image = self.transform(image)
        
        return image, label

def create_gtsrb_models():
    """åˆ›å»ºGTSRBæµ‹è¯•æ¨¡å‹"""
    print("ğŸ” åˆ›å»ºGTSRBæµ‹è¯•æ¨¡å‹...")
    
    # æ¨¡å‹1: ä¿®å¤çš„é¢œè‰²å¤´
    class FixedColorHead(nn.Module):
        def __init__(self, input_dim=64, num_classes=43):
            super().__init__()
            self.input_dim = input_dim
            self.num_classes = num_classes
            
            # é¢œè‰²ç‰¹å¾æå–å™¨
            self.color_extractor = nn.Sequential(
                nn.Linear(input_dim, 256),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(256, 128),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(128, 64),
                nn.ReLU()
            )
            
            # é¢œè‰²åˆ†ç±»å™¨
            self.color_classifier = nn.Sequential(
                nn.Linear(64, 128),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(128, 64),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(64, num_classes)
            )
            
            self._initialize_weights()
        
        def _initialize_weights(self):
            for m in self.modules():
                if isinstance(m, nn.Linear):
                    nn.init.xavier_uniform_(m.weight)
                    if m.bias is not None:
                        nn.init.constant_(m.bias, 0)
        
        def forward(self, x):
            # é¢œè‰²ç‰¹å¾æå–
            color_features = self.color_extractor(x)
            
            # é¢œè‰²è¯­ä¹‰é¢„æµ‹
            color_logits = self.color_classifier(color_features)
            
            return {
                'color_semantic_logits': color_logits,
                'color_features': color_features,
                'features': x
            }
        
        def compute_loss(self, outputs, targets, images=None):
            """ä¿®å¤çš„æŸå¤±å‡½æ•°"""
            color_logits = outputs['color_semantic_logits']
            loss = nn.CrossEntropyLoss()(color_logits, targets)
            
            return {
                'total_loss': loss,
                'main_loss': loss
            }
    
    # æ¨¡å‹2: åŸºç¡€æ¨¡å‹
    class BaseModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.features = nn.Sequential(
                nn.Linear(3072, 1024),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(1024, 512),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(512, 256),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(256, 128),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(128, 43)
            )
            
            self._initialize_weights()
        
        def _initialize_weights(self):
            for m in self.modules():
                if isinstance(m, nn.Linear):
                    nn.init.xavier_uniform_(m.weight)
                    if m.bias is not None:
                        nn.init.constant_(m.bias, 0)
        
        def forward(self, x):
            x = x.view(x.size(0), -1)
            return {'logits': self.features(x)}
    
    # æ¨¡å‹3: é›†æˆæ¨¡å‹
    class EnsembleModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.base_model = BaseModel()
            self.color_head = FixedColorHead()
            
            # å¯å­¦ä¹ çš„èåˆæƒé‡
            self.fusion_weight = nn.Parameter(torch.tensor(0.5))
            
        def forward(self, x):
            # åŸºç¡€æ¨¡å‹é¢„æµ‹
            base_outputs = self.base_model(x)
            base_logits = base_outputs['logits']
            
            # é¢œè‰²å¤´é¢„æµ‹
            features = x.view(x.size(0), -1)[:, :64]
            color_outputs = self.color_head(features)
            color_logits = color_outputs['color_semantic_logits']
            
            # èåˆé¢„æµ‹
            fusion_weight = torch.sigmoid(self.fusion_weight)
            final_logits = fusion_weight * base_logits + (1 - fusion_weight) * color_logits
            
            return {
                'final_logits': final_logits,
                'base_logits': base_logits,
                'color_logits': color_logits,
                'fusion_weight': fusion_weight
            }
        
        def compute_loss(self, outputs, targets, images=None):
            """é›†æˆæŸå¤±å‡½æ•°"""
            final_logits = outputs['final_logits']
            loss = nn.CrossEntropyLoss()(final_logits, targets)
            
            return {
                'total_loss': loss,
                'main_loss': loss
            }
    
    fixed_color_head = FixedColorHead()
    base_model = BaseModel()
    ensemble_model = EnsembleModel()
    
    return fixed_color_head, base_model, ensemble_model

def train_gtsrb_model(model, train_loader, val_loader, model_name, device, epochs=20):
    """è®­ç»ƒGTSRBæ¨¡å‹"""
    print(f"ğŸ” å¼€å§‹è®­ç»ƒ {model_name}...")
    
    # ä¼˜åŒ–å™¨è®¾ç½®
    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
    
    # å­¦ä¹ ç‡è°ƒåº¦
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.5)
    
    # æŸå¤±å‡½æ•°
    criterion = nn.CrossEntropyLoss()
    
    # è®­ç»ƒå†å²
    train_history = {'loss': [], 'accuracy': []}
    val_history = {'loss': [], 'accuracy': []}
    
    best_accuracy = 0.0
    patience = 5
    patience_counter = 0
    
    for epoch in range(epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        for batch_idx, (data, targets) in enumerate(train_loader):
            data, targets = data.to(device), targets.to(device)
            
            # å‰å‘ä¼ æ’­
            if hasattr(model, 'compute_loss'):
                if hasattr(model, 'color_head'):  # é›†æˆæ¨¡å‹
                    outputs = model(data)
                    loss_dict = model.compute_loss(outputs, targets, data)
                    loss = loss_dict['total_loss']
                    _, predicted = outputs['final_logits'].max(1)
                else:  # é¢œè‰²å¤´
                    features = data.view(data.size(0), -1)[:, :64]
                    outputs = model(features)
                    loss_dict = model.compute_loss(outputs, targets, data)
                    loss = loss_dict['total_loss']
                    _, predicted = outputs['color_semantic_logits'].max(1)
            else:
                outputs = model(data)
                loss = criterion(outputs['logits'], targets)
                _, predicted = outputs['logits'].max(1)
            
            # æ£€æŸ¥æŸå¤±å€¼
            if torch.isnan(loss) or torch.isinf(loss) or loss.item() < 0:
                print(f"âš ï¸ è­¦å‘Š: å¼‚å¸¸æŸå¤±å€¼ {loss.item()}")
                continue
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # ç»Ÿè®¡
            train_loss += loss.item()
            train_total += targets.size(0)
            train_correct += predicted.eq(targets).sum().item()
            
            if batch_idx % 50 == 0:
                print(f"  Epoch {epoch+1}/{epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}")
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for data, targets in val_loader:
                data, targets = data.to(device), targets.to(device)
                
                if hasattr(model, 'compute_loss'):
                    if hasattr(model, 'color_head'):  # é›†æˆæ¨¡å‹
                        outputs = model(data)
                        loss_dict = model.compute_loss(outputs, targets, data)
                        loss = loss_dict['total_loss']
                        _, predicted = outputs['final_logits'].max(1)
                    else:  # é¢œè‰²å¤´
                        features = data.view(data.size(0), -1)[:, :64]
                        outputs = model(features)
                        loss_dict = model.compute_loss(outputs, targets, data)
                        loss = loss_dict['total_loss']
                        _, predicted = outputs['color_semantic_logits'].max(1)
                else:
                    outputs = model(data)
                    loss = criterion(outputs['logits'], targets)
                    _, predicted = outputs['logits'].max(1)
                
                val_loss += loss.item()
                val_total += targets.size(0)
                val_correct += predicted.eq(targets).sum().item()
        
        # è®¡ç®—å‡†ç¡®ç‡
        train_accuracy = 100. * train_correct / train_total
        val_accuracy = 100. * val_correct / val_total
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # è®°å½•å†å²
        train_history['loss'].append(train_loss / len(train_loader))
        train_history['accuracy'].append(train_accuracy)
        val_history['loss'].append(val_loss / len(val_loader))
        val_history['accuracy'].append(val_accuracy)
        
        print(f"  Epoch {epoch+1}/{epochs}: Train Loss: {train_loss/len(train_loader):.4f}, "
              f"Train Acc: {train_accuracy:.2f}%, Val Loss: {val_loss/len(val_loader):.4f}, "
              f"Val Acc: {val_accuracy:.2f}%")
        
        # æ—©åœæœºåˆ¶
        if val_accuracy > best_accuracy:
            best_accuracy = val_accuracy
            torch.save(model.state_dict(), f"best_gtsrb_{model_name.replace(' ', '_')}.pth")
            print(f"  ğŸ‰ æ–°çš„æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2f}%")
            patience_counter = 0
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print(f"  â¹ï¸ æ—©åœè§¦å‘ï¼Œæœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2f}%")
                break
    
    return train_history, val_history, best_accuracy

def run_real_gtsrb_test():
    """è¿è¡ŒçœŸå®GTSRBæµ‹è¯•"""
    print("ğŸ” å¼€å§‹çœŸå®GTSRBæµ‹è¯•")
    print("="*80)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # ä¸‹è½½/åŠ è½½GTSRBæ•°æ®é›†
    data_root = '/home/hding22/gtsrb_color_project/data'
    gtsrb_dir = download_gtsrb_data(data_root)
    
    if gtsrb_dir is None:
        print("âŒ æ— æ³•è·å–GTSRBæ•°æ®é›†")
        return
    
    # åˆ›å»ºæ•°æ®é›†
    print("ğŸ” åˆ›å»ºGTSRBæ•°æ®é›†...")
    train_dataset = GTSRBDataset(gtsrb_dir, split='train', img_size=32)
    val_dataset = GTSRBDataset(gtsrb_dir, split='val', img_size=32)
    
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)
    
    print(f"æ•°æ®é›†å¤§å°: è®­ç»ƒ {len(train_dataset)}, éªŒè¯ {len(val_dataset)}")
    
    # åˆ›å»ºæ¨¡å‹
    fixed_color_head, base_model, ensemble_model = create_gtsrb_models()
    fixed_color_head = fixed_color_head.to(device)
    base_model = base_model.to(device)
    ensemble_model = ensemble_model.to(device)
    
    results = {}
    
    # å®éªŒ1: ä¿®å¤çš„é¢œè‰²å¤´
    print(f"\nğŸ”¬ å®éªŒ1: ä¿®å¤çš„é¢œè‰²å¤´")
    start_time = time.time()
    color_train_history, color_val_history, color_best_accuracy = train_gtsrb_model(
        fixed_color_head, train_loader, val_loader, "ä¿®å¤é¢œè‰²å¤´", device, epochs=20
    )
    color_training_time = time.time() - start_time
    
    results['fixed_color_head'] = {
        'best_accuracy': color_best_accuracy,
        'training_time': color_training_time,
        'train_history': color_train_history,
        'val_history': color_val_history
    }
    
    print(f"ä¿®å¤é¢œè‰²å¤´ç»“æœ: {color_best_accuracy:.2f}% ({color_training_time:.2f}ç§’)")
    
    # å®éªŒ2: åŸºç¡€æ¨¡å‹
    print(f"\nğŸ”¬ å®éªŒ2: åŸºç¡€æ¨¡å‹")
    start_time = time.time()
    base_train_history, base_val_history, base_best_accuracy = train_gtsrb_model(
        base_model, train_loader, val_loader, "åŸºç¡€æ¨¡å‹", device, epochs=20
    )
    base_training_time = time.time() - start_time
    
    results['base_model'] = {
        'best_accuracy': base_best_accuracy,
        'training_time': base_training_time,
        'train_history': base_train_history,
        'val_history': base_val_history
    }
    
    print(f"åŸºç¡€æ¨¡å‹ç»“æœ: {base_best_accuracy:.2f}% ({base_training_time:.2f}ç§’)")
    
    # å®éªŒ3: é›†æˆæ¨¡å‹
    print(f"\nğŸ”¬ å®éªŒ3: é›†æˆæ¨¡å‹")
    start_time = time.time()
    ensemble_train_history, ensemble_val_history, ensemble_best_accuracy = train_gtsrb_model(
        ensemble_model, train_loader, val_loader, "é›†æˆæ¨¡å‹", device, epochs=20
    )
    ensemble_training_time = time.time() - start_time
    
    results['ensemble_model'] = {
        'best_accuracy': ensemble_best_accuracy,
        'training_time': ensemble_training_time,
        'train_history': ensemble_train_history,
        'val_history': ensemble_val_history
    }
    
    print(f"é›†æˆæ¨¡å‹ç»“æœ: {ensemble_best_accuracy:.2f}% ({ensemble_training_time:.2f}ç§’)")
    
    # ç»“æœæ€»ç»“
    print(f"\nğŸ“Š çœŸå®GTSRBæµ‹è¯•ç»“æœæ€»ç»“")
    print("="*60)
    
    print(f"æ¨¡å‹å¯¹æ¯”:")
    print(f"  ä¿®å¤é¢œè‰²å¤´: {results['fixed_color_head']['best_accuracy']:.2f}%")
    print(f"  åŸºç¡€æ¨¡å‹: {results['base_model']['best_accuracy']:.2f}%")
    print(f"  é›†æˆæ¨¡å‹: {results['ensemble_model']['best_accuracy']:.2f}%")
    
    # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
    best_model = max(results.keys(), key=lambda k: results[k]['best_accuracy'])
    best_accuracy = results[best_model]['best_accuracy']
    
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model} ({best_accuracy:.2f}%)")
    
    # æ€§èƒ½åˆ†æ
    print(f"\nğŸ¯ æ€§èƒ½åˆ†æ:")
    print(f"  ç›¸å¯¹éšæœºçŒœæµ‹: {best_accuracy/2.33:.1f}å€")
    print(f"  é¢œè‰²å¤´ç›¸å¯¹åŸºç¡€æ¨¡å‹: {results['fixed_color_head']['best_accuracy'] - results['base_model']['best_accuracy']:.2f}%")
    
    if results['fixed_color_head']['best_accuracy'] > results['base_model']['best_accuracy']:
        print("âœ… é¢œè‰²å¤´è¡¨ç°æ›´å¥½ï¼")
    else:
        print("âš ï¸ åŸºç¡€æ¨¡å‹è¡¨ç°æ›´å¥½")
    
    # ä¿å­˜ç»“æœ
    with open("real_gtsrb_results.json", 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: real_gtsrb_results.json")
    print("ğŸ‰ çœŸå®GTSRBæµ‹è¯•å®Œæˆ!")
    
    return results

if __name__ == '__main__':
    run_real_gtsrb_test()

