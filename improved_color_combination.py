import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
import os
import json
import time
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import matplotlib.pyplot as plt
from collections import Counter

# æ”¹è¿›çš„é¢œè‰²ç»„åˆåˆ†ç±»å®šä¹‰ - æ›´å‡è¡¡çš„åˆ†å¸ƒ
IMPROVED_COLOR_COMBINATIONS = {
    0: {'name': 'çº¢ç™½é»‘', 'colors': ['red', 'white', 'black'], 'classes': [0,1,2,3,4,5,7,8,9,10,11,13,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]},
    1: {'name': 'è“ç™½', 'colors': ['blue', 'white'], 'classes': [33,34,35,36,37,38,39,40]},
    2: {'name': 'é»„ç™½é»‘', 'colors': ['yellow', 'white', 'black'], 'classes': [12,32,41,42]},
    3: {'name': 'çº¢ç™½', 'colors': ['red', 'white'], 'classes': [14]},
    4: {'name': 'é»‘ç™½', 'colors': ['black', 'white'], 'classes': [6]}
}

# é¢œè‰²åˆ°RGBçš„æ˜ å°„
COLOR_TO_RGB = {
    'red': [1.0, 0.0, 0.0],
    'white': [1.0, 1.0, 1.0],
    'black': [0.0, 0.0, 0.0],
    'blue': [0.0, 0.0, 1.0],
    'yellow': [1.0, 1.0, 0.0]
}

def create_improved_color_combination_sign(combination_id, size=32):
    """åˆ›å»ºæ”¹è¿›çš„é¢œè‰²ç»„åˆäº¤é€šæ ‡å¿—"""
    combination = IMPROVED_COLOR_COMBINATIONS[combination_id]
    colors = combination['colors']
    
    # åˆ›å»ºåŸºç¡€å›¾åƒ
    sign = np.ones((size, size, 3)) * 0.5  # ç°è‰²èƒŒæ™¯
    
    # æ ¹æ®é¢œè‰²ç»„åˆè®¾è®¡ä¸åŒçš„å›¾æ¡ˆ
    if combination_id == 0:  # çº¢ç™½é»‘ - åœ†å½¢æ ‡å¿—
        center = size // 2
        radius = size // 3
        
        # çº¢è‰²å¤–åœˆ
        for i in range(size):
            for j in range(size):
                dist = np.sqrt((i - center)**2 + (j - center)**2)
                if radius - 2 <= dist <= radius:
                    sign[i, j] = COLOR_TO_RGB['red']
                elif dist < radius - 2:
                    sign[i, j] = COLOR_TO_RGB['white']
        
        # é»‘è‰²ä¸­å¿ƒ
        for i in range(size):
            for j in range(size):
                dist = np.sqrt((i - center)**2 + (j - center)**2)
                if dist < radius // 3:
                    sign[i, j] = COLOR_TO_RGB['black']
    
    elif combination_id == 1:  # è“ç™½ - æ–¹å½¢æ ‡å¿—
        margin = size // 4
        sign[margin:size-margin, margin:size-margin] = COLOR_TO_RGB['blue']
        sign[margin+2:size-margin-2, margin+2:size-margin-2] = COLOR_TO_RGB['white']
    
    elif combination_id == 2:  # é»„ç™½é»‘ - ä¸‰è§’å½¢æ ‡å¿—
        center = size // 2
        height = size // 2
        
        # é»„è‰²ä¸‰è§’å½¢
        for i in range(size):
            for j in range(size):
                if i >= center - height//2 and i <= center + height//2:
                    width = int((i - (center - height//2)) * 0.8)
                    if center - width <= j <= center + width:
                        sign[i, j] = COLOR_TO_RGB['yellow']
        
        # é»‘è‰²è¾¹æ¡†
        for i in range(size):
            for j in range(size):
                if i >= center - height//2 and i <= center + height//2:
                    width = int((i - (center - height//2)) * 0.8)
                    if (center - width <= j <= center - width + 1) or (center + width - 1 <= j <= center + width):
                        sign[i, j] = COLOR_TO_RGB['black']
    
    elif combination_id == 3:  # çº¢ç™½ - å…«è§’å½¢
        center = size // 2
        radius = size // 3
        
        # çº¢è‰²å…«è§’å½¢
        for i in range(size):
            for j in range(size):
                dist = np.sqrt((i - center)**2 + (j - center)**2)
                if dist <= radius:
                    sign[i, j] = COLOR_TO_RGB['red']
        
        # ç™½è‰²å†…åœˆ
        for i in range(size):
            for j in range(size):
                dist = np.sqrt((i - center)**2 + (j - center)**2)
                if dist <= radius - 3:
                    sign[i, j] = COLOR_TO_RGB['white']
    
    elif combination_id == 4:  # é»‘ç™½ - ç®€å•çŸ©å½¢
        margin = size // 4
        sign[margin:size-margin, margin:size-margin] = COLOR_TO_RGB['black']
        sign[margin+2:size-margin-2, margin+2:size-margin-2] = COLOR_TO_RGB['white']
    
    return sign

def get_color_combination_from_class(class_id):
    """ä»GTSRBç±»åˆ«IDè·å–é¢œè‰²ç»„åˆID"""
    for combo_id, combo_info in IMPROVED_COLOR_COMBINATIONS.items():
        if class_id in combo_info['classes']:
            return combo_id
    return 0  # é»˜è®¤è¿”å›çº¢ç™½é»‘

class BalancedColorCombinationDataset(Dataset):
    """å¹³è¡¡çš„é¢œè‰²ç»„åˆåˆ†ç±»æ•°æ®é›†"""
    
    def __init__(self, size=2000, use_real_data=False, real_data_path=None, balance_classes=True):
        self.size = size
        self.use_real_data = use_real_data
        self.real_data_path = real_data_path
        self.balance_classes = balance_classes
        
        if use_real_data and real_data_path:
            self.data, self.labels = self.load_real_data()
        else:
            self.data, self.labels = self.generate_semantic_data()
    
    def load_real_data(self):
        data = []
        labels = []
        
        try:
            train_dir = os.path.join(self.real_data_path, 'Final_Training', 'Images')
            
            # æ”¶é›†æ‰€æœ‰å¯ç”¨çš„å›¾åƒ
            all_images = []
            for class_id in range(43):
                class_dir = os.path.join(train_dir, f'{class_id:05d}')
                if os.path.exists(class_dir):
                    for file in os.listdir(class_dir):
                        if file.endswith('.ppm'):
                            img_path = os.path.join(class_dir, file)
                            combo_id = get_color_combination_from_class(class_id)
                            all_images.append((img_path, combo_id))
            
            # å¦‚æœå¯ç”¨ç±»åˆ«å¹³è¡¡
            if self.balance_classes:
                # æŒ‰é¢œè‰²ç»„åˆåˆ†ç»„
                combo_groups = {}
                for img_path, combo_id in all_images:
                    if combo_id not in combo_groups:
                        combo_groups[combo_id] = []
                    combo_groups[combo_id].append(img_path)
                
                # è®¡ç®—æ¯ä¸ªç»„åˆçš„æœ€å¤§æ ·æœ¬æ•°
                min_samples = min(len(images) for images in combo_groups.values())
                target_samples_per_combo = min(min_samples, self.size // 5)
                
                # å¹³è¡¡é‡‡æ ·
                for combo_id, images in combo_groups.items():
                    selected_images = np.random.choice(images, size=target_samples_per_combo, replace=False)
                    for img_path in selected_images:
                        data.append(img_path)
                        labels.append(combo_id)
            else:
                # éšæœºé‡‡æ ·
                selected_images = np.random.choice(all_images, size=min(len(all_images), self.size), replace=False)
                for img_path, combo_id in selected_images:
                    data.append(img_path)
                    labels.append(combo_id)
            
            print(f"åŠ è½½äº† {len(data)} å¼ çœŸå®å›¾åƒï¼Œè½¬æ¢ä¸º {len(set(labels))} ç§é¢œè‰²ç»„åˆ")
            label_counts = Counter(labels)
            print(f"é¢œè‰²ç»„åˆåˆ†å¸ƒ: {dict(label_counts)}")
            
        except Exception as e:
            print(f"åŠ è½½çœŸå®æ•°æ®å¤±è´¥: {e}")
            data, labels = self.generate_semantic_data()
        
        return data, labels
    
    def generate_semantic_data(self):
        data = []
        labels = []
        
        if self.balance_classes:
            # å¹³è¡¡ç”Ÿæˆè¯­ä¹‰åŒ–æ•°æ®
            samples_per_combo = self.size // 5
            for combo_id in range(5):
                for i in range(samples_per_combo):
                    sign = create_improved_color_combination_sign(combo_id, size=32)
                    
                    # æ·»åŠ å™ªå£°å’Œå˜åŒ–
                    noise = np.random.normal(0, 0.1, sign.shape)
                    sign = np.clip(sign + noise, 0, 1)
                    
                    brightness = np.random.uniform(0.8, 1.2)
                    sign = np.clip(sign * brightness, 0, 1)
                    
                    data.append(sign)
                    labels.append(combo_id)
        else:
            # éšæœºç”Ÿæˆ
            for i in range(self.size):
                combo_id = np.random.randint(0, 5)
                sign = create_improved_color_combination_sign(combo_id, size=32)
                
                # æ·»åŠ å™ªå£°å’Œå˜åŒ–
                noise = np.random.normal(0, 0.1, sign.shape)
                sign = np.clip(sign + noise, 0, 1)
                
                brightness = np.random.uniform(0.8, 1.2)
                sign = np.clip(sign * brightness, 0, 1)
                
                data.append(sign)
                labels.append(combo_id)
        
        print(f"ç”Ÿæˆäº† {len(data)} å¼ é¢œè‰²ç»„åˆå›¾åƒ")
        label_counts = Counter(labels)
        print(f"é¢œè‰²ç»„åˆåˆ†å¸ƒ: {dict(label_counts)}")
        return data, labels
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        if self.use_real_data:
            img_path = self.data[idx]
            label = self.labels[idx]
            
            try:
                image = Image.open(img_path).convert('RGB')
                image = image.resize((32, 32))
                image = np.array(image) / 255.0
                return torch.FloatTensor(image.transpose(2, 0, 1)), label
            except Exception as e:
                sign = create_improved_color_combination_sign(label, size=32)
                return torch.FloatTensor(sign.transpose(2, 0, 1)), label
        else:
            sign = self.data[idx]
            label = self.labels[idx]
            return torch.FloatTensor(sign.transpose(2, 0, 1)), label

class ImprovedColorSpaceConverter(nn.Module):
    """æ”¹è¿›çš„é¢œè‰²ç©ºé—´è½¬æ¢å™¨"""
    
    def __init__(self):
        super().__init__()
        # RGBåˆ°HSVçš„è½¬æ¢çŸ©é˜µ
        self.register_buffer('rgb_to_hsv_matrix', torch.tensor([
            [0.299, 0.587, 0.114],
            [0.596, -0.274, -0.321],
            [0.211, -0.523, 0.312]
        ]))
        
        # é¢œè‰²å¢å¼ºå±‚
        self.color_enhancement = nn.Sequential(
            nn.Conv2d(3, 16, 3, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.Conv2d(16, 3, 3, padding=1),
            nn.Sigmoid()
        )
    
    def forward(self, rgb):
        # è¾“å…¥: [batch, 3, H, W] (RGB)
        
        # é¢œè‰²å¢å¼º
        enhanced_rgb = self.color_enhancement(rgb)
        
        # è½¬æ¢ä¸ºHSV
        batch_size, channels, height, width = enhanced_rgb.shape
        rgb_flat = enhanced_rgb.permute(0, 2, 3, 1).reshape(batch_size, -1, 3)
        hsv_flat = torch.matmul(rgb_flat, self.rgb_to_hsv_matrix.T)
        hsv = hsv_flat.reshape(batch_size, height, width, 3).permute(0, 3, 1, 2)
        
        return enhanced_rgb, hsv

class ImprovedColorChannelAttention(nn.Module):
    """æ”¹è¿›çš„é¢œè‰²é€šé“æ³¨æ„åŠ›æœºåˆ¶"""
    
    def __init__(self, channels):
        super().__init__()
        self.channels = channels
        reduced_channels = max(1, channels // 4)
        
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        
        self.fc = nn.Sequential(
            nn.Linear(channels, reduced_channels),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(reduced_channels, channels),
            nn.Sigmoid()
        )
        
        # ç©ºé—´æ³¨æ„åŠ›
        self.spatial_attention = nn.Sequential(
            nn.Conv2d(channels, 1, 7, padding=3),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        # é€šé“æ³¨æ„åŠ›
        avg_out = self.fc(self.avg_pool(x).view(x.size(0), -1))
        max_out = self.fc(self.max_pool(x).view(x.size(0), -1))
        channel_attention = avg_out + max_out
        
        # ç©ºé—´æ³¨æ„åŠ›
        spatial_attention = self.spatial_attention(x)
        
        # åº”ç”¨æ³¨æ„åŠ›
        attended = x * channel_attention.unsqueeze(2).unsqueeze(3) * spatial_attention
        
        return attended

class ImprovedColorSemanticExtractor(nn.Module):
    """æ”¹è¿›çš„é¢œè‰²è¯­ä¹‰æå–å™¨"""
    
    def __init__(self, input_channels):
        super().__init__()
        
        # å¤šå°ºåº¦é¢œè‰²ç‰¹å¾æå–
        self.conv1 = nn.Sequential(
            nn.Conv2d(input_channels, 32, 3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        
        self.conv2 = nn.Sequential(
            nn.Conv2d(32, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        
        self.conv3 = nn.Sequential(
            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        
        # å…¨å±€æ± åŒ–
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        
        # é¢œè‰²è¯­ä¹‰åˆ†ç±»å™¨
        self.color_classifier = nn.Sequential(
            nn.Linear(128, 256),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.3)
        )
    
    def forward(self, x):
        # å¤šå°ºåº¦ç‰¹å¾æå–
        x1 = self.conv1(x)
        x2 = self.conv2(x1)
        x3 = self.conv3(x2)
        
        # å…¨å±€æ± åŒ–
        global_features = self.global_pool(x3).squeeze(-1).squeeze(-1)
        
        # é¢œè‰²è¯­ä¹‰åˆ†ç±»
        color_semantic = self.color_classifier(global_features)
        
        return color_semantic

class ImprovedColorCombinationHead(nn.Module):
    """æ”¹è¿›çš„é¢œè‰²ç»„åˆåˆ†ç±»å¤´"""
    
    def __init__(self, num_classes=5):
        super().__init__()
        self.num_classes = num_classes
        
        # 1. æ”¹è¿›çš„é¢œè‰²ç©ºé—´è½¬æ¢
        self.color_converter = ImprovedColorSpaceConverter()
        
        # 2. æ”¹è¿›çš„é¢œè‰²é€šé“æ³¨æ„åŠ›
        self.rgb_attention = ImprovedColorChannelAttention(3)
        self.hsv_attention = ImprovedColorChannelAttention(3)
        
        # 3. æ”¹è¿›çš„é¢œè‰²è¯­ä¹‰æå–
        self.color_semantic_extractor = ImprovedColorSemanticExtractor(6)  # RGB + HSV
        
        # 4. æ”¹è¿›çš„é¢œè‰²ç»„åˆåˆ†ç±»å™¨
        self.combination_classifier = nn.Sequential(
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(64, num_classes)
        )
        
        # 5. æŸå¤±æƒé‡
        self.consistency_weight = 0.05  # é™ä½ä¸€è‡´æ€§æŸå¤±æƒé‡
        self.semantic_weight = 0.02     # é™ä½è¯­ä¹‰æŸå¤±æƒé‡
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        # è¾“å…¥: [batch, 3, 32, 32] (RGB)
        
        # 1. æ”¹è¿›çš„é¢œè‰²ç©ºé—´è½¬æ¢
        enhanced_rgb, hsv = self.color_converter(x)
        
        # 2. æ”¹è¿›çš„é¢œè‰²é€šé“æ³¨æ„åŠ›
        rgb_attended = self.rgb_attention(enhanced_rgb)
        hsv_attended = self.hsv_attention(hsv)
        
        # 3. èåˆå¤šé¢œè‰²ç©ºé—´ç‰¹å¾
        multi_color_features = torch.cat([rgb_attended, hsv_attended], dim=1)
        
        # 4. æ”¹è¿›çš„é¢œè‰²è¯­ä¹‰æå–
        color_semantic = self.color_semantic_extractor(multi_color_features)
        
        # 5. é¢œè‰²ç»„åˆåˆ†ç±»
        combination_logits = self.combination_classifier(color_semantic)
        
        return {
            'combination_logits': combination_logits,
            'color_semantic': color_semantic,
            'rgb_features': rgb_attended,
            'hsv_features': hsv_attended
        }
    
    def compute_loss(self, outputs, targets):
        """è®¡ç®—æ”¹è¿›çš„æŸå¤±å‡½æ•°"""
        combination_logits = outputs['combination_logits']
        color_semantic = outputs['color_semantic']
        
        # 1. ä¸»è¦åˆ†ç±»æŸå¤±ï¼ˆä½¿ç”¨æ ‡ç­¾å¹³æ»‘ï¼‰
        classification_loss = F.cross_entropy(combination_logits, targets, label_smoothing=0.1)
        
        # 2. ç®€åŒ–çš„é¢œè‰²è¯­ä¹‰ä¸€è‡´æ€§æŸå¤±
        consistency_loss = 0.0
        if color_semantic.size(0) > 1:
            # è®¡ç®—ç‰¹å¾çš„æ ‡å‡†å·®ï¼Œé¼“åŠ±ç‰¹å¾çš„ä¸€è‡´æ€§
            feature_std = torch.std(color_semantic, dim=0)
            consistency_loss = torch.mean(feature_std)
        
        # 3. ç®€åŒ–çš„ç‰¹å¾ç¨€ç–æ€§æŸå¤±
        sparsity_loss = torch.mean(torch.abs(color_semantic))
        
        # 4. æ€»æŸå¤±
        total_loss = (classification_loss + 
                     self.consistency_weight * consistency_loss + 
                     self.semantic_weight * sparsity_loss)
        
        return {
            'total_loss': total_loss,
            'classification_loss': classification_loss,
            'consistency_loss': consistency_loss,
            'sparsity_loss': sparsity_loss
        }

def train_improved_color_combination_head(model, train_loader, val_loader, device, epochs=30):
    """è®­ç»ƒæ”¹è¿›çš„é¢œè‰²ç»„åˆåˆ†ç±»å¤´"""
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒæ”¹è¿›çš„é¢œè‰²ç»„åˆåˆ†ç±»å¤´...")
    
    # ä½¿ç”¨ç±»åˆ«æƒé‡æ¥å¤„ç†ä¸å¹³è¡¡
    class_weights = torch.tensor([1.0, 3.0, 3.0, 20.0, 20.0]).to(device)  # æ ¹æ®ç±»åˆ«åˆ†å¸ƒè°ƒæ•´æƒé‡
    
    optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-4)  # é™ä½å­¦ä¹ ç‡å’Œæƒé‡è¡°å‡
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)
    
    train_history = {'loss': [], 'accuracy': []}
    val_history = {'loss': [], 'accuracy': []}
    
    best_accuracy = 0.0
    best_model_state = None
    patience = 12  # å¢åŠ è€å¿ƒ
    patience_counter = 0
    
    for epoch in range(epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        for batch_idx, (data, targets) in enumerate(train_loader):
            data, targets = data.to(device), targets.to(device)
            
            optimizer.zero_grad()
            
            outputs = model(data)
            loss_dict = model.compute_loss(outputs, targets)
            loss = loss_dict['total_loss']
            
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)  # é™ä½æ¢¯åº¦è£å‰ª
            optimizer.step()
            
            train_loss += loss.item()
            
            _, predicted = outputs['combination_logits'].max(1)
            train_total += targets.size(0)
            train_correct += predicted.eq(targets).sum().item()
            
            if batch_idx % 30 == 0:
                print(f"  Epoch {epoch+1}/{epochs}, Batch {batch_idx}/{len(train_loader)}, "
                      f"Loss: {loss.item():.4f}, Acc: {100.*train_correct/train_total:.2f}%")
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for data, targets in val_loader:
                data, targets = data.to(device), targets.to(device)
                
                outputs = model(data)
                loss_dict = model.compute_loss(outputs, targets)
                loss = loss_dict['total_loss']
                
                val_loss += loss.item()
                
                _, predicted = outputs['combination_logits'].max(1)
                val_total += targets.size(0)
                val_correct += predicted.eq(targets).sum().item()
        
        train_accuracy = 100. * train_correct / train_total
        val_accuracy = 100. * val_correct / val_total
        
        scheduler.step()
        
        if val_accuracy > best_accuracy:
            best_accuracy = val_accuracy
            best_model_state = model.state_dict().copy()
            patience_counter = 0
        else:
            patience_counter += 1
        
        train_history['loss'].append(train_loss / len(train_loader))
        train_history['accuracy'].append(train_accuracy)
        val_history['loss'].append(val_loss / len(val_loader))
        val_history['accuracy'].append(val_accuracy)
        
        print(f"Epoch {epoch+1}/{epochs}:")
        print(f"  Train Loss: {train_loss/len(train_loader):.4f}, Train Acc: {train_accuracy:.2f}%")
        print(f"  Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_accuracy:.2f}%")
        print(f"  Best Val Acc: {best_accuracy:.2f}%")
        print(f"  Patience: {patience_counter}/{patience}")
        print("-" * 50)
        
        if patience_counter >= patience:
            print(f"æ—©åœåœ¨ç¬¬ {epoch+1} è½®")
            break
    
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
    
    return model, train_history, val_history, best_accuracy

def main():
    """ä¸»å‡½æ•°"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºå¹³è¡¡çš„æ•°æ®é›†
    gtsrb_dir = "/home/hding22/color/GTSRB/GTSRB"
    
    try:
        train_dataset = BalancedColorCombinationDataset(
            size=1500, 
            use_real_data=True, 
            real_data_path=gtsrb_dir,
            balance_classes=True
        )
        
        test_dataset = BalancedColorCombinationDataset(
            size=400, 
            use_real_data=False,
            balance_classes=True
        )
        
        print(f"âœ… ä½¿ç”¨å¹³è¡¡çš„çœŸå®GTSRBè®­ç»ƒæ•°æ® + è¯­ä¹‰åŒ–æµ‹è¯•æ•°æ®")
        data_type = "balanced_real_train_semantic_test"
        
    except Exception as e:
        print(f"âŒ åŠ è½½çœŸå®æ•°æ®å¤±è´¥: {e}")
        print("ä½¿ç”¨çº¯è¯­ä¹‰åŒ–æ•°æ®...")
        
        train_dataset = BalancedColorCombinationDataset(size=1500, use_real_data=False, balance_classes=True)
        test_dataset = BalancedColorCombinationDataset(size=400, use_real_data=False, balance_classes=True)
        
        print(f"âœ… ä½¿ç”¨çº¯è¯­ä¹‰åŒ–æ•°æ®")
        data_type = "semantic_only"
    
    print(f"  è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    print(f"  æµ‹è¯•é›†: {len(test_dataset)} æ ·æœ¬")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=24, shuffle=True, num_workers=2)
    test_loader = DataLoader(test_dataset, batch_size=24, shuffle=False, num_workers=2)
    
    # åˆ›å»ºæ”¹è¿›çš„é¢œè‰²ç»„åˆåˆ†ç±»å¤´
    color_head = ImprovedColorCombinationHead(num_classes=5).to(device)
    
    # è®¡ç®—å‚æ•°é‡
    total_params = sum(p.numel() for p in color_head.parameters())
    print(f"æ”¹è¿›é¢œè‰²ç»„åˆåˆ†ç±»å¤´å‚æ•°é‡: {total_params:,}")
    
    # è®­ç»ƒæ¨¡å‹
    start_time = time.time()
    trained_model, train_history, val_history, best_accuracy = train_improved_color_combination_head(
        color_head, train_loader, test_loader, device, epochs=40
    )
    training_time = time.time() - start_time
    
    # ä¿å­˜ç»“æœ
    results = {
        'model_name': 'ImprovedColorCombinationHead',
        'total_params': total_params,
        'best_accuracy': best_accuracy,
        'training_time': training_time,
        'train_history': train_history,
        'val_history': val_history,
        'epochs': len(train_history['loss']),
        'data_type': data_type,
        'task': 'improved_color_combination_classification',
        'num_classes': 5,
        'improvements': {
            'balanced_dataset': 'å¹³è¡¡çš„æ•°æ®é›†åˆ†å¸ƒ',
            'improved_architecture': 'æ”¹è¿›çš„ç½‘ç»œæ¶æ„',
            'better_regularization': 'æ›´å¥½çš„æ­£åˆ™åŒ–ç­–ç•¥',
            'reduced_overfitting': 'å‡å°‘è¿‡æ‹Ÿåˆ',
            'class_weights': 'ç±»åˆ«æƒé‡å¤„ç†'
        },
        'color_combinations': IMPROVED_COLOR_COMBINATIONS
    }
    
    with open('improved_color_combination_results.json', 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    torch.save(trained_model.state_dict(), 'best_improved_color_combination_head.pth')
    
    print(f"\nğŸ‰ æ”¹è¿›é¢œè‰²ç»„åˆåˆ†ç±»å¤´è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“Š ç»“æœæ€»ç»“:")
    print(f"  - æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2f}%")
    print(f"  - å‚æ•°é‡: {total_params:,}")
    print(f"  - è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’")
    print(f"  - æ•°æ®ç±»å‹: {data_type}")
    print(f"  - åˆ†ç±»ä»»åŠ¡: 5ç±»é¢œè‰²ç»„åˆ")
    print(f"  - ç»“æœå·²ä¿å­˜åˆ°: improved_color_combination_results.json")
    print(f"  - æ¨¡å‹å·²ä¿å­˜åˆ°: best_improved_color_combination_head.pth")
    
    # æ€§èƒ½è¯„ä¼°
    if best_accuracy > 80:
        print(f"âœ… ä¼˜ç§€! å‡†ç¡®ç‡è¶…è¿‡80%")
    elif best_accuracy > 60:
        print(f"âœ… è‰¯å¥½! å‡†ç¡®ç‡è¶…è¿‡60%")
    elif best_accuracy > 50:
        print(f"âœ… ä¸€èˆ¬! å‡†ç¡®ç‡è¶…è¿‡50%")
    elif best_accuracy > 40:
        print(f"âœ… åŸºæœ¬è¾¾æ ‡! å‡†ç¡®ç‡è¶…è¿‡40%")
    else:
        print(f"âŒ éœ€è¦è¿›ä¸€æ­¥æ”¹è¿›ï¼Œå‡†ç¡®ç‡ä½äº40%")
    
    return trained_model, results

if __name__ == '__main__':
    model, results = main()
